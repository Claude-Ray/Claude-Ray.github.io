<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Claude&#39;s Home</title>
  <subtitle>Searching</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://claude-ray.github.io/"/>
  <updated>2019-05-24T15:21:44.243Z</updated>
  <id>https://claude-ray.github.io/</id>
  
  <author>
    <name>Claude Ray</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>让 Node.js Server 优雅退出</title>
    <link href="https://claude-ray.github.io/2019/05/23/node-graceful-server/"/>
    <id>https://claude-ray.github.io/2019/05/23/node-graceful-server/</id>
    <published>2019-05-23T07:12:28.000Z</published>
    <updated>2019-05-24T15:21:44.243Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>服务进程登场时往往“蓄势而发”，犹抱琵琶半遮面，真正的服务端口跑起来之前做了太多准备工作，然而落幕工作常被人草草了之。</p>
<p>如何让进程自然结束，这本是 hello world 级的基础内容，却有很多项目忽视了这一步的必要性以及重要性。</p>
<p>目前使用 PM2 作为进程管理的项目仍占多数，有相关意识的朋友使用 <code>pm2 reload</code> 让进程“平滑”重启，但这就不需要额外的代码处理了吗？</p>
<p>举个例子，未捕获的异常导致服务强行退出时，是不是有可能进程尚未记录异常日志、请求执行到了一半、甚至中断了更复杂的业务工作？PM2 只能截住新的请求，旧的请求是否彻底执行完毕，仍需要业务自己判断。</p>
<p>下面我们先抛开 PM2 ，聊聊基本的进程退出需要哪些工作。首先我们从未捕获的异常说起。</p>
<a id="more"></a>
<h2 id="uncaughtException"><a href="#uncaughtException" class="headerlink" title="uncaughtException"></a>uncaughtException</h2><p>在进程退场前做好日志记录工作，算是基本需求之一。</p>
<blockquote>
<p>预先约定，本篇示例代码中出现的 <code>logger</code> 均为 log4js 或 console 等日志模块的伪代码。</p>
</blockquote>
<p>默认情况下，控制台打印 <code>Uncaught exception xxx</code> 之后直接退出。如果是用 log4js 记录日志到文件或推送远程日志库，不好意思，很可能发现记录中什么错误信息都没留下。</p>
<p>优雅退出的核心方法是调用 <a href="https://nodejs.org/api/net.html#net_server_close_callback" target="_blank" rel="noopener">server.close([callback])</a>，用于停止 server 接受建立新的连接，并保持已经存在的连接。当所有的连接关闭同时 server 响应 ‘close’ 事件时，server 才会最终关闭，并调用回调函数（可选的）。另外, 如果服务器在未开启状态下执行 close，将会抛出 error 作为回调函数的唯一参数。</p>
<p>在 close 回调函数里可确保没有未结束的请求，也就能放心结束进程。网上随处可见的最基本的处理版本如下：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">process.on(<span class="string">'uncaughtException'</span>, <span class="keyword">async</span> err =&gt; &#123;</span><br><span class="line">  logger.error(<span class="string">`Uncaught exception:`</span>, err)</span><br><span class="line">  server.close(<span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">    logger.info(<span class="string">'Server is closed'</span>)</span><br><span class="line">    process.exit(<span class="number">1</span>)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>然而这离我们的目标还有段距离，代码运行一段时间就会遇到问题，异常记录是有了，server 迟迟没有退出的迹象。因为有很多 http 请求是 keep-alive 的，只要这些连接释放不掉，server 就无法 close，同时会有源源不断的新请求进来。</p>
<p>这也是为什么有人采用 setTimeout 计时强制关闭超时的 server.close。然而 setTimeout 方式治标不治本，既然阻塞退出的根源是 keep-alive 没能立刻关闭，就通过 <a href="https://nodejs.org/api/http.html#http_server_keepalivetimeout" target="_blank" rel="noopener">server.keepAliveTimeout</a> (新增于v8.0.0) 缩短其持续的时间吧。</p>
<p>另外，我们为了把可能的错误都收集起来，server.close 的异常也放到在日志中去(然而，Node.js 只会在这里抛出一种错误，并且后面会证明这一步没什么必要)。</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">process.on(<span class="string">'uncaughtException'</span>, <span class="keyword">async</span> err =&gt; &#123;</span><br><span class="line">  logger.fatal(<span class="string">`Uncaught exception:`</span>, err)</span><br><span class="line">  server.keepAliveTimeout = <span class="number">1</span></span><br><span class="line">  server.close(<span class="function"><span class="params">e</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (e) &#123;</span><br><span class="line">      logger.error(<span class="string">'Error while server is closing'</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">    logger.info(<span class="string">'Server is closed'</span>)</span><br><span class="line">    process.exit(<span class="number">1</span>)</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">  setTimeout(<span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">    logger.warn(<span class="string">'Server close timeout! Process exit 1'</span>)</span><br><span class="line">    process.exit(<span class="number">1</span>)</span><br><span class="line">  &#125;, <span class="number">10000</span>)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>上面的代码依然保留了 setTimeout 的退出方式，避免有时候真的出现特殊异常。</p>
<p>接下来我就介绍一种导致关闭失败的情况：该 server 被用来建立了 websocket 连接，如果不显示执行 sockets 的 close 方法，仍然被认为有连接未被释放。因此，不得不再加上socket的处理。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">io.sockets.server.close()</span><br></pre></td></tr></table></figure></p>
<p>好吧，进程终于可以正常退出了，这就完了吗？当然没有！</p>
<p>如果程序中还保持着 mysql，redis 等等服务的连接，或者有异步的操作的话，继续等这些连接关闭、任务执行完毕吧。</p>
<h2 id="unhandledRejection"><a href="#unhandledRejection" class="headerlink" title="unhandledRejection"></a>unhandledRejection</h2><p>再提一下 unhandledRejection，尽管目前 Node.js 不会因此而主动退出进程，但将来会。</p>
<blockquote>
<p>In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code</p>
</blockquote>
<p>业务最好做一下适当把控，最起码，监听这个事件是有助于自定义的日志记录。之前的 uncaughtException 也同样适用。</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">process.on(<span class="string">'unhandledRejection'</span>, <span class="keyword">async</span> err =&gt; &#123;</span><br><span class="line">  logger.error(<span class="string">`Unhandle Promise rejection:`</span>, err)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="SIGINT"><a href="#SIGINT" class="headerlink" title="SIGINT"></a>SIGINT</h2><p>说完了异常退出，别忘了正常退出，最常见的事件是 <code>SIGINT</code>，使用 PM2 停止或重启进程时就会触发。</p>
<p>但处理起来保持和 uncaughtException 一致就好了，除了这里的 exit code 应该是 0。</p>
<h2 id="PM2-Graceful-Shutdown"><a href="#PM2-Graceful-Shutdown" class="headerlink" title="PM2 Graceful Shutdown"></a>PM2 Graceful Shutdown</h2><p>有工具自然要好好利用，但 PM2 不止有 reload。</p>
<p>写到这里，笔者犯懒了，文档链接先放这，有时间再考虑搬运，请按需自取 XD</p>
<p><a href="https://pm2.io/doc/en/runtime/best-practices/graceful-shutdown/" target="_blank" rel="noopener">https://pm2.io/doc/en/runtime/best-practices/graceful-shutdown/</a></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>综上，进程退场要做的事情其实并不少，日志的记录方式依赖于实际技术栈，不太容易封装成通用的库，一般得结合自身框架定制。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;服务进程登场时往往“蓄势而发”，犹抱琵琶半遮面，真正的服务端口跑起来之前做了太多准备工作，然而落幕工作常被人草草了之。&lt;/p&gt;
&lt;p&gt;如何让进程自然结束，这本是 hello world 级的基础内容，却有很多项目忽视了这一步的必要性以及重要性。&lt;/p&gt;
&lt;p&gt;目前使用 PM2 作为进程管理的项目仍占多数，有相关意识的朋友使用 &lt;code&gt;pm2 reload&lt;/code&gt; 让进程“平滑”重启，但这就不需要额外的代码处理了吗？&lt;/p&gt;
&lt;p&gt;举个例子，未捕获的异常导致服务强行退出时，是不是有可能进程尚未记录异常日志、请求执行到了一半、甚至中断了更复杂的业务工作？PM2 只能截住新的请求，旧的请求是否彻底执行完毕，仍需要业务自己判断。&lt;/p&gt;
&lt;p&gt;下面我们先抛开 PM2 ，聊聊基本的进程退出需要哪些工作。首先我们从未捕获的异常说起。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Node.js" scheme="https://claude-ray.github.io/tags/Node-js/"/>
    
      <category term="graceful-server" scheme="https://claude-ray.github.io/tags/graceful-server/"/>
    
      <category term="pm2" scheme="https://claude-ray.github.io/tags/pm2/"/>
    
  </entry>
  
  <entry>
    <title>Node.js APM 产品调研</title>
    <link href="https://claude-ray.github.io/2019/05/19/node-apm-product-research/"/>
    <id>https://claude-ray.github.io/2019/05/19/node-apm-product-research/</id>
    <published>2019-05-19T13:52:35.000Z</published>
    <updated>2019-05-21T14:30:54.574Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><a href="https://en.wikipedia.org/wiki/Application_performance_management" target="_blank" rel="noopener">Application Performance Management</a>（简称 APM）是监控服务的一套技术手段，致力于监控并管理程序的性能和可用性。</p>
<p>不妨思考一下，当有用户反映操作无响应，如何排查问题？惯例是先自己尝试重现，如果没重现，再换一个人试试，bla bla…</p>
<p>从用户击下按键开始，到服务呈现最终效果的过程中，有哪些因素会导致阻塞？</p>
<p>是否真的未响应？有没有可能是网络过慢导致？</p>
<p>丢包？用户网络质量还是机房故障？出现在机群哪一层？</p>
<p>代码BUG？自己的还是别人的？</p>
<p>能快速定位是哪一环节出了问题吗？</p>
<p>用户的请求从客户端 -&gt; CDN -&gt; 代理 -&gt; 中间层 -&gt; 服务1 -&gt; 服务2 -&gt; …</p>
<p>线上应用的性能表现是极为复杂的，运维的感知总是慢于业务，人工监控或草木皆兵、或亡羊补牢。因此需要一个合理的监控措施以便诊断服务质量，提高运维和业务的工作效率，间接服务于提升用户体验。</p>
<p>尽管上面的例子和请求链路相关，许多人就将 APM 和 <code>分布式链路跟踪系统</code> 混为一谈，其实并不恰当。 APM 当然可以承载 Tracing 工作，但除此之外还包含内存、CPU、RT、TPS、QPS等等监控职能，链路分析仅是其中一环罢了。为了更清晰地阐述，下面先简单介绍一下 APM 的基本定义。</p>
<h2 id="关于-APM"><a href="#关于-APM" class="headerlink" title="关于 APM"></a>关于 APM</h2><p>APM 是 <code>Gartner</code> 抽象出的一个管理模型，有如下定义。</p>
<p><img src="/image/node-apm-product-research/apm-coneptual-framework.jpg" alt="APM Coneptual Framework"></p>
<p>通俗的说法如下</p>
<ol>
<li>终端用户体验：反馈真实用户的体验，包括高峰时的服务、组件平均响应时间。</li>
<li>应用架构映射：能否分析真实请求链路。</li>
<li>应用事务分析：要求有序、完整地记录事务信息，能够定位两个操作是否为同一个用户，且信息具备唯一性。</li>
<li>深度应用诊断：用户反馈问题时，能精准定位问题点，通常需要做更底层的监控。同时又有着部署简单、副作用低的要求，这是 APM 应用的主要难点所在。</li>
<li>分析与报告：数据要实时且精准，大数据的存储与查询，目前已经不难应对。</li>
</ol>
<p>2016 年， Gartner 又将上述 5 个维度更新为 3 个新维度。</p>
<ul>
<li>数字体验监控 (DEM)：对应用户体验监控</li>
<li>应用发现、跟踪、诊断 (ADTD)：整合并了应用架构映射、事务分析、深度应用诊断</li>
<li>应用分析 (AA)：对应分析与报告</li>
</ul>
<p>除了 DEM ，基本概念和旧维度呈对应关系，为了方便理解，下面提一下 Gartner 对 DEM 的定义。</p>
<blockquote>
<p>an availability and performance monitoring discipline that supports the optimization of the operational experience and behavior of a digital agent, human or machine, as it interacts with enterprise applications and services. For the purposes of this evaluation, it includes real-user monitoring (RUM) and synthetic transaction monitoring (STM) for both web- and mobile-based end users.</p>
</blockquote>
<p>实质依然是通过用户的角度分析关键业务（RUM），通过测试消除潜在的错误和性能瓶颈（STM），以数字化增强监控分析能力。</p>
<h1 id="主流-APM-简介"><a href="#主流-APM-简介" class="headerlink" title="主流 APM 简介"></a>主流 APM 简介</h1><h2 id="商业软件"><a href="#商业软件" class="headerlink" title="商业软件"></a>商业软件</h2><h3 id="New-Relic"><a href="#New-Relic" class="headerlink" title="New Relic"></a>New Relic</h3><blockquote>
<p><a href="https://newrelic.com/nodejs" target="_blank" rel="noopener">https://newrelic.com/nodejs</a></p>
</blockquote>
<p>New Relic 是绝对专业的 APM 公司，并凭借其技术产品 2014 年上市，且不说其他版本的 APM，在 Node.js 领域是绝对的 APM 龙头。虽然监控服务需要付费，在云端才能使用，但其 SDK 源代码完全开放，可以清晰地看到它对各探针的实现，对接入方开发者十分友好，也因此成为各监控服务的模仿对象。</p>
<p>是付费用户的首选。</p>
<h3 id="AppDynamics"><a href="#AppDynamics" class="headerlink" title="AppDynamics"></a>AppDynamics</h3><blockquote>
<p><a href="https://www.appdynamics.com/nodejs" target="_blank" rel="noopener">https://www.appdynamics.com/nodejs</a></p>
</blockquote>
<p>AppDynamics 一直是 New Relic 的竞争对手，有意思的是，两家公司的创始人分别是来自同一家公司的首席架构师、CEO ，并在同一年创立。</p>
<p>AppDynamics 公司在 2016 年上市，它提供的服务也非常强大，但和 New Relic 的市场定位不同，New Relic 初期战略主要针对小型创业公司，而 AppDynamics 则专攻企业。且 AppDynamics 可以在公司内部数据中心运行，而不只是作为云端服务。</p>
<p>其 SDK 代码不完全开放，部分使用了 jar 包和二进制文件。</p>
<h3 id="Dynatrace"><a href="#Dynatrace" class="headerlink" title="Dynatrace"></a>Dynatrace</h3><blockquote>
<p><a href="https://www.dynatrace.com/technologies/nodejs-monitoring/" target="_blank" rel="noopener">https://www.dynatrace.com/technologies/nodejs-monitoring/</a></p>
</blockquote>
<p>Dynatrace 和 New Relic、AppDynamics 并称为 APM 产业三大领军者，但在 Node.js 的市场占有率和热度很低，不开放源代码，无法深度化定制，难以认可它已经是成熟的产品。</p>
<h3 id="atatus"><a href="#atatus" class="headerlink" title="atatus"></a>atatus</h3><blockquote>
<p><a href="https://www.atatus.com/for/nodejs" target="_blank" rel="noopener">https://www.atatus.com/for/nodejs</a></p>
</blockquote>
<p>支持功能一般，只能算二线产品，况且其 SDK 做了代码混淆。</p>
<h3 id="听云"><a href="#听云" class="headerlink" title="听云"></a>听云</h3><blockquote>
<p><a href="https://doc.tingyun.com/server/html/node/install.html" target="_blank" rel="noopener">https://doc.tingyun.com/server/html/node/install.html</a></p>
</blockquote>
<p>国内团队，可以限量免费试用。估计很多人体验过，其很多功能（代码）借鉴自 New Relic ，功能相仿，好在做了一些针对性地强化，不过多介绍。</p>
<p>有 New Relic 做“后盾”，服务不会差到哪去，小型团队不妨一用。</p>
<h3 id="oneapm"><a href="#oneapm" class="headerlink" title="oneapm"></a>oneapm</h3><blockquote>
<p><a href="https://www.oneapm.com/ai/nodejs.html" target="_blank" rel="noopener">https://www.oneapm.com/ai/nodejs.html</a></p>
</blockquote>
<p>有兴趣的话自己了解吧。因为乱打广告，SDK 几乎照搬 New Relic，不太讨喜，可以感受到其团队水平不如听云。</p>
<h2 id="开源免费方案"><a href="#开源免费方案" class="headerlink" title="开源免费方案"></a>开源免费方案</h2><h3 id="Alinode"><a href="#Alinode" class="headerlink" title="Alinode"></a>Alinode</h3><p>由于这个方案存在较多争议，因此额外给了一些篇幅补充介绍。</p>
<h4 id="开发者介绍"><a href="#开发者介绍" class="headerlink" title="开发者介绍"></a>开发者介绍</h4><p>hyj1991 解释过 Alinode 对 Node Runtime 增加了哪些改动：</p>
<ul>
<li>增加了一些 V8 没有对外暴露的接口，比如 GC Trace 来动态输出 GC 日志</li>
<li>埋了一些点以性能损耗更低的方式采集进程级别的 CPU 和 Memory 数据</li>
<li>增加了动态开启 CPU / Memory / GC 状态采集的开关</li>
</ul>
<p>而对于负责开发者业务相关的 API 和功能逻辑，并无任何改动，这也是为什么 AliNode 和官方的 Runtime 可以无缝对切的原因。</p>
<p>至于安全问题，主要是担心会采集业务数据上报，但是实际上 AliNode 内核的上述改动，都不会直接向云端发送任何数据，而都是以本地 Log 的方式写入大家配置的 NODE_LOG_DIR 目录下，日志文件以 <code>node-日志.log</code> 的形式命名，不放心的话可以查看此文件内容。</p>
<p>实际上大家在控制台看到的数据，最后不管使用的是 egg-alinode 还是 agenthub 均是通过 agentx 这个库采集上报的，这个库首先它是开源的，大家可以自行阅读相关采集代码观察是否上报了敏感数据。最后实在对安全问题存在疑虑的，可以通过 Wireshark 等抓包工具，来抓取 AliNode 输出的日志和 Agentx 上报的数据内容，看看是否上报的数据中存在大家非常担心的敏感数据。</p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>严格来说 Alinode 不能算作开源方案，但其实它只有后台和启动代码是闭源的，尤其对小团队而言接入成本低，是非常值得考虑的接入方案。</p>
<p>而且由于日志收集进程开源，除了没有开源的收集 v8 内部性能的功能，其他信息都可以通过接入自己的日志系统或后台进行分析。</p>
<p>但从企业角度出发，还是完全由自己掌控的方案更放心。</p>
<h3 id="Easy-Monitor"><a href="#Easy-Monitor" class="headerlink" title="Easy Monitor"></a>Easy Monitor</h3><blockquote>
<p><a href="https://github.com/hyj1991/easy-monitor" target="_blank" rel="noopener">https://github.com/hyj1991/easy-monitor</a></p>
</blockquote>
<p>终于提到了一个完全开源的方案了，它的开发者同样是 hyj1991，可惜功能实在简单，仅提供性能监控，维护度较低。</p>
<p>目前最大的价值是作为学习项目，而不是投入生产环境。</p>
<h3 id="Pandora-js"><a href="#Pandora-js" class="headerlink" title="Pandora.js"></a>Pandora.js</h3><blockquote>
<p><a href="https://midwayjs.org/pandora/zh-cn/" target="_blank" rel="noopener">https://midwayjs.org/pandora/zh-cn/</a></p>
</blockquote>
<p>来自阿里 midwayjs 团队，是类似于 PM2 的一个启动进程，因此最大优点是无代码侵入。</p>
<p>目前功能尚不完备，支持star、restart、stop，调试时为了查看 debugger 记录，可加上 <code>--inspect</code> 参数，暂不支持平滑 reload。</p>
<p>Dashboard 只能单机部署单机监控，无法集群监控，目前 midway 的使用方案是结合 ElasticSearch。</p>
<p>据说已经在阿里内部落地，现在正重构 2.0 版本，等待此项目成熟可考虑使用。很希望能替代臃肿的 PM2。</p>
<h3 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h3><blockquote>
<p><a href="https://prometheus.io/" target="_blank" rel="noopener">https://prometheus.io/</a></p>
</blockquote>
<p>在国外非常流行，相比业务方，更多地被运维熟知，是一种监控和报警的开源生态。SDK 和界面有多重组合方式，Node.js 一般结合 <code>prom-client</code>(非官方 npm 包) + <code>Granfana</code> 使用。</p>
<p>只做性能采集，不支持 trace 跟踪。目前已知缺陷是内存占用较高和日志量巨大，数据可以选择本地存储或远程接口存储。</p>
<p>开源的一大选择方案，落地可能对运维团队要求较高。</p>
<h3 id="Elastic-APM"><a href="#Elastic-APM" class="headerlink" title="Elastic APM"></a>Elastic APM</h3><blockquote>
<p><a href="https://www.elastic.co/solutions/apm" target="_blank" rel="noopener">https://www.elastic.co/solutions/apm</a></p>
</blockquote>
<ul>
<li>APM: <a href="https://www.elastic.co/guide/en/apm/get-started/current/index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/apm/get-started/current/index.html</a></li>
<li>Node Client: <a href="https://www.elastic.co/guide/en/apm/agent/nodejs/current/index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/apm/agent/nodejs/current/index.html</a></li>
<li>Kibana APM: <a href="https://www.elastic.co/guide/en/kibana/current/xpack-apm.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/kibana/current/xpack-apm.html</a></li>
</ul>
<p>这是 Elastic 体系下的完全开源的 APM 解决方案，也提供商业付费服务。文档一如既往地丰富，上面列举了其中三个入口。</p>
<p>日志采集进程为 golang 编写的 apm-server，最终将数据存储到 ElasticSearch，Kibana 内置了 APM 基础看板。</p>
<p>官方提供 API 来支持深度定制，golang 降低了二次开发的成本，更不用担心 Kibana 看板功能不够用。总之，是相当全面的解决方案，之后会单独开一篇文章介绍。</p>
<h1 id="选型概述"><a href="#选型概述" class="headerlink" title="选型概述"></a>选型概述</h1><h2 id="要点维度"><a href="#要点维度" class="headerlink" title="要点维度"></a>要点维度</h2><h3 id="性能监控"><a href="#性能监控" class="headerlink" title="性能监控"></a>性能监控</h3><p>进程级的 CPU、内存指标监控，这是 APM 最基本功能，普遍支持。</p>
<p>更高级的是 V8 监控，heap 信息，做出 profile 等诊断。但实际上 Node 最新版本已经暴露出 V8 heap 的接口，profile 也完全可以需要时主动创建，重要性反而不是特别高。</p>
<h3 id="代码级监控"><a href="#代码级监控" class="headerlink" title="代码级监控"></a>代码级监控</h3><p>监控到代码细节，不是简单的错误定位，而是分析哪段代码有内存泄露、提供 SQL 慢查询日志等更实用的功能。</p>
<h3 id="事务监控"><a href="#事务监控" class="headerlink" title="事务监控"></a>事务监控</h3><p>分析业务流程、请求响应时间等。</p>
<h3 id="框架支持"><a href="#框架支持" class="headerlink" title="框架支持"></a>框架支持</h3><p>要实现对 npm 依赖的监控，例如路由的追踪，是需要明确定制化到特定包的，例如 express、koa、bluebird、sequelize 等。</p>
<p>这里只考虑了主流的 Express 和 Koa HTTP 框架，有特殊需要的请进一步到官方了解。</p>
<h3 id="链路追踪"><a href="#链路追踪" class="headerlink" title="链路追踪"></a>链路追踪</h3><p>一个请求从创建到响应的链路分析。</p>
<h3 id="分布式部署"><a href="#分布式部署" class="headerlink" title="分布式部署"></a>分布式部署</h3><p>能否识别集群的部署状况。</p>
<h3 id="外部依赖"><a href="#外部依赖" class="headerlink" title="外部依赖"></a>外部依赖</h3><p>需要哪些数据库等外部依赖。</p>
<h3 id="代码侵入"><a href="#代码侵入" class="headerlink" title="代码侵入"></a>代码侵入</h3><p>对代码侵入程度越低，接入越方便，避免对业务造成影响。</p>
<p>除了引入 SDK 的方式，是否有使用 async hook，是否对第三方库做了热 Patch，类似 Java 动态字节码探针，都可能对业务形成一定隐患。</p>
<h3 id="社区活跃度"><a href="#社区活跃度" class="headerlink" title="社区活跃度"></a>社区活跃度</h3><p>分技术层面的参考，但还是很重要的指标。可以参考 npm 最近一个月的平局周下载量。</p>
<h2 id="关于-Node-js"><a href="#关于-Node-js" class="headerlink" title="关于 Node.js"></a>关于 Node.js</h2><p>Node.js 在服务端尤其是中间层表现不俗，但如果经验不足的情况下将 Node 落地，没有任何监控，承担的风险太大。</p>
<p>小团队的发布流程和运维支撑通常较弱，难以避免线上故障，这一阶段，快速响应和处理才能降低损失。</p>
<p>考虑到 APM 的接入成本，有必要分清接入功能的优先级。</p>
<p>在虚拟化、容器化的现在，大部分性能指标的采集工作都可以在业务之外进行，因此性能采集只要能做到进程级的监控即可。</p>
<p>分布式全链路追踪，不是只在 Node 一端接入就有效果的，必然是根据运维和后端技术栈，选择使用 Zipkin 等更合理的开源方案。</p>
<p>如果上面的观点你还算认可，那么我们选型上应该更关注 APM 服务对代码级监控的支持力度、侵入程度、社区活跃度和接入成本。</p>
<h2 id="选型"><a href="#选型" class="headerlink" title="选型"></a>选型</h2><p>综上，APM 的选型参考如下</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>Express</th>
<th>Koa</th>
<th>性能</th>
<th>代码级</th>
<th>事务</th>
<th>链路</th>
<th>分布式</th>
<th>侵入</th>
<th>实现方式</th>
<th>npm周下载量(+)</th>
</tr>
</thead>
<tbody>
<tr>
<td>newrelic</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>中</td>
<td>探针</td>
<td>30.1k</td>
</tr>
<tr>
<td>appdynamics</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>中</td>
<td>探针</td>
<td>9.5k</td>
</tr>
<tr>
<td>dynatrace</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>中</td>
<td>探针</td>
<td>0.1k</td>
</tr>
<tr>
<td>atatus</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>×</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>中</td>
<td>探针</td>
<td>0.6k</td>
</tr>
<tr>
<td>tingyun</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>中</td>
<td>探针</td>
<td>0.3k</td>
</tr>
<tr>
<td>one apm</td>
<td>✓</td>
<td>×</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>中</td>
<td>探针</td>
<td>0.1k</td>
</tr>
<tr>
<td>alinode</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>无</td>
<td>run time</td>
<td>-</td>
</tr>
<tr>
<td>easy monitor</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>×</td>
<td>×</td>
<td>×</td>
<td>✓</td>
<td>低</td>
<td>探针</td>
<td>0.1k</td>
</tr>
<tr>
<td>pandora</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>×</td>
<td>✓</td>
<td>✓</td>
<td>×</td>
<td>低</td>
<td>进程启动器</td>
<td>0.2k</td>
</tr>
<tr>
<td>Prometheus</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>×</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>中</td>
<td>探针</td>
<td>20.1k</td>
</tr>
<tr>
<td>elastic apm</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>×</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td>中</td>
<td>探针</td>
<td>24.6k</td>
</tr>
</tbody>
</table>
<h2 id="自研"><a href="#自研" class="headerlink" title="自研"></a>自研</h2><p>普遍场景下，在日志层面做好业务监控即可，参考下面的流程，只要不涉及 Stack、SQL 等代码级监控，就能以较低开发成本、低侵入式地实现核心业务监控。</p>
<ol>
<li>基于 Node.js 自带的 API 完成探针，并在关键业务做好相关埋点，将数据(日志)打点到 Kafka。</li>
<li>另起服务进程，专门消费 Kafka 的监控队列，推送到 ElasticSearch 服务中。</li>
<li>通过 Kibana 的看板完成一系列定制化的数据分析。</li>
</ol>
<p>如果是更复杂的需求，则不建议造轮子，而是基于开源方案二次开发。</p>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>无论如何，我更倾向选用开源方案，但目前开原方案的代码级监控都是短板，那么这也成为自研和深度定制的困难所在。</p>
<p>末尾重申，APM 属于运维技术的范畴，业务方自己搭建时，最好结合自身需求定制，当心过犹不及。</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://en.wikipedia.org/wiki/Application_performance_management" target="_blank" rel="noopener">维基百科-Application performance management</a></li>
<li><a href="http://network.51cto.com/art/201503/469273.htm" target="_blank" rel="noopener">什么是真正的APM？</a></li>
<li><a href="https://www.zhihu.com/question/315261662" target="_blank" rel="noopener">关于Nodejs的性能监控思考？</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      近期调研了当下 Node.js 主流的 APM 产品，为期不到一周，本文以介绍基本状况为主，引申对 APM 中间件选型乃至自研的一些思考。APM 虽和业务关系紧密，但实属于运维管理范畴，笔者从业务的角度思考，易受限于使用场景，请路过的读者及时指教问题。
    
    </summary>
    
      <category term="Node.js" scheme="https://claude-ray.github.io/categories/Node-js/"/>
    
    
      <category term="Node.js" scheme="https://claude-ray.github.io/tags/Node-js/"/>
    
      <category term="APM" scheme="https://claude-ray.github.io/tags/APM/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 分页查询优化思路</title>
    <link href="https://claude-ray.github.io/2019/03/11/mysql-pagination/"/>
    <id>https://claude-ray.github.io/2019/03/11/mysql-pagination/</id>
    <published>2019-03-11T14:11:05.000Z</published>
    <updated>2019-03-14T14:14:55.003Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>突破查询瓶颈的方法有很多，但这里先不谈分库分表之流，当头问题就一个：单数据表分页查询过慢怎么办？</p>
<p>其实讲分页优化的博客真不少，但很多博主只顾分享点子忽略了细节，还有很多值得补充的地方。笔者回顾了曾经在千万级 BBS 项目的优化经历，尽可能结合实际地聊聊个人对分页查询的见解。也希望读者在亲身操作中验证，任何优化脱离了实际场景都是纸上谈兵。</p>
<a id="more"></a>
<h2 id="分页方式"><a href="#分页方式" class="headerlink" title="分页方式"></a>分页方式</h2><p>首先介绍最常见的数据分页方式，即传统分页和流式分页。</p>
<h3 id="传统分页"><a href="#传统分页" class="headerlink" title="传统分页"></a>传统分页</h3><p><img src="/image/mysql-pagination/01.png" alt="贴吧PC分页"></p>
<p>传统分页的基本逻辑是每页展示固定的条目数、通过页码分页和翻页，包含要素如下：</p>
<ul>
<li>首页：按序查询出一页长度的数据，作为顶部数据，无须处理偏移量。</li>
<li>下一页：除了末页都有下一页。通过页数能确定当前数据的偏移量，和数据总数比较可以判断是否还有下一页。偏移量可用于获取下一页的信息。</li>
<li>上一页：除了首页都有上一页。其余同上。</li>
<li>跳转：同上，偏移量来判断是否支持跳转到该页。</li>
<li>总页数：只要记住数据总量，除一下就能得到页数。结合跳转功能使用。</li>
<li>末页：许多系统会支持跳转到最后一页，根据总页数或总量即可实现。</li>
</ul>
<p>翻页和跳转功能为查询效率带来了极大挑战，一方面带着偏移量的 MySQL 查询效率不高，另一方面功能上也存在缺陷，例如浏览当前页面的过程中发生数据新增或删除，页码编号已经重置，此时翻页后会出现数据“重复”或“缺失”的问题。</p>
<h3 id="流式分页"><a href="#流式分页" class="headerlink" title="流式分页"></a>流式分页</h3><p><img src="/image/mysql-pagination/02.png" alt="贴吧Mobile分页"></p>
<p>流式分页简单得多，即只能一页一页向下加载，偏移量不固定，不提供跳转。常见于移动端，它不仅解决了传统分页的功能缺陷，间接对查询性能有所提升。</p>
<p>因此分页设计时产品层的优化必不可少，尽量选择流式分页。</p>
<p>不过 BBS 类型的 Web 项目为了方便用户，奉行 PC 端使用传统分页，移动端使用流式分页的设计理念。如果对这种设计没概念，可以左转百度贴吧。这要求我们必须直面传统分页带来的性能挑战。</p>
<h2 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h2><p>索引优化的套路属于另一个范畴了，应当视具体引擎、数据分布、锁等信息来权衡处理。在这里主要强调一点，使用覆盖索引避免回表查询。因为 InnoDB 查询偏移量 offset 的过程是先查出 offset + limit 条数据，再抛弃前 offset 条数据，偏移量过大时查询效率将低到令人发指。</p>
<p>因此，必须禁止分页查询时使用<code>select *</code>，充分利用索引中存储的信息，才能避免大量的回表取值操作。</p>
<p>不必追求一次查询得到完整结果，如果索引不包含待查询的字段，只查出主键 id 亦可，如下：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> table_name</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> create_time <span class="keyword">desc</span></span><br><span class="line"><span class="keyword">limit</span> <span class="number">10000</span>,<span class="number">10</span>;</span><br></pre></td></tr></table></figure></p>
<p>拿到 id 的集合后，大部分博客的处理都将这一步作为子查询，使用 <code>in</code>、<code>join</code> 或<code>比较符</code>继续查出数据详情。</p>
<p>但我们应当慎用子查询，尽量将查 id 和查数据分开进行，这便于之后的<a href="#缓存优化">缓存优化</a>。</p>
<h2 id="缓存优化"><a href="#缓存优化" class="headerlink" title="缓存优化"></a>缓存优化</h2><p>要提升查询效率，最终实现的效果必然是所有查询都命中缓存。</p>
<p>为了避免频繁使用 count()，数据总数应当放在缓存中，但同时也破坏了一致性。如果你十分看重总数目的准确性，注意加上定时任务或缓存淘汰等同步机制。</p>
<p>对分页数据的缓存，不要直接以页数存储整页数据，否则任何数据的增减都将使所有页缓存作废。</p>
<p>区分开哪些内容是频繁更新的、哪些是相对稳定的。相对一页应该存哪几条数据，具体数据内容的更新频率低很多，因此较好的做法是使用 hash 缓存每一页的 id 列表，使用 string (whatever) 缓存每一条数据。</p>
<p>拿到 id 列表之后，无需回表，可直接到 redis 获取对应信息。</p>
<blockquote>
<p>另外针对新手提醒一点，不要 for 循环查询 redis，多次请求 redis 的网络开销得不偿失。可以使用 pipeline 将一串请求包起来，且整个管道操作是非原子的，不会阻塞 redis。至于另一类原生批量操作是原子的，如 mget，会阻塞其他 redis 操作。</p>
</blockquote>
<h2 id="末页优化"><a href="#末页优化" class="headerlink" title="末页优化"></a>末页优化</h2><p>尽管理论上 B+Tree 近乎二分查找，但对于有较大复杂度的数据表，不可能为每种查询都建立最优索引。优化到一定程度后索引数量和效率的折中就是拆东墙补西墙了，最终很可能威胁到某个 sql 的大偏移量查询。而末页查询恰好是 offset 最大的时候。</p>
<p>喜欢翻旧账的可能人不多，但看到“最后一页”按钮时，恐怕没几个人能忍住不点一下。这个按钮的受欢迎程度就算不如“第二页”，也肯定超过“四五六七八…页”。</p>
<p>不少的点击量加大了数据的查询压力，若是查询过慢导致内容半天加载不出来，更会诱发用户主动刷新发起更多请求。想想就够恐怖的。</p>
<p>笔者在使用才 500 万的数据做复杂查询时，offset 效率就又一次成为瓶颈。但查询第一页的效率总是非常快，那只要保证末页的速度达到和首页一样快，也就能达成优化目标。具体做法看下面的 sql ：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> table_name</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> create_time <span class="keyword">asc</span></span><br><span class="line"><span class="keyword">limit</span> <span class="number">10</span>;</span><br></pre></td></tr></table></figure>
<p><code>反向排序</code> 实现了末页等同于首页查询效率的效果。截止到 5.7 版本，MySQL 并没有在索引上区分 asc 和 desc，因此不需要新建索引，即可享用另一面的极速查询！</p>
<p>而且不仅仅是末页，实际上只要判断出偏移量超过总数目的一半，就可以进行反向 order 了。</p>
<p>注意此时得到一页数据的顺序也是反过来的，别忘了对该列表做个反转。除此之外，这种查询会导致最后一页永远是“排满”的，如有必要，可借助总数量修正最后一页应显示的条数，这样末页看起来和优化前一个样儿了。</p>
<p>也许是需要这么处理的场景比较少，最近只在这篇<a href="http://seanlook.com/2018/03/21/mysql-pagination-no-offset/" target="_blank" rel="noopener">文章</a>看到了相同的做法，该作者对优化细节的讲解更多，推荐一下。</p>
<h2 id="no-offset"><a href="#no-offset" class="headerlink" title="no offset"></a>no offset</h2><p>有 offset 的地方就有坑，干脆不要用了！服务端缓存好每一页的最小 id 确实问题不大，用 <code>&gt;</code>、<code>&lt;</code> 的效率比 offset 高多了。可惜按时间排序的数据 id 不一定是递增的，增删过后的更新难度较大。</p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>搜索引擎不一定能优化分页效率，例如 Elasticsearch 要通过集群各个节点的搜集才能查到偏移量之后的数据……</p>
<p>最后，任何不严谨的地方恳请斧正。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;突破查询瓶颈的方法有很多，但这里先不谈分库分表之流，当头问题就一个：单数据表分页查询过慢怎么办？&lt;/p&gt;
&lt;p&gt;其实讲分页优化的博客真不少，但很多博主只顾分享点子忽略了细节，还有很多值得补充的地方。笔者回顾了曾经在千万级 BBS 项目的优化经历，尽可能结合实际地聊聊个人对分页查询的见解。也希望读者在亲身操作中验证，任何优化脱离了实际场景都是纸上谈兵。&lt;/p&gt;
    
    </summary>
    
      <category term="MySQL" scheme="https://claude-ray.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="https://claude-ray.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>当 bind_ip:127.0.0.1 遇上 Debian 的默认 host</title>
    <link href="https://claude-ray.github.io/2019/02/21/bindip-debian-hostname/"/>
    <id>https://claude-ray.github.io/2019/02/21/bindip-debian-hostname/</id>
    <published>2019-02-21T13:35:43.000Z</published>
    <updated>2019-03-03T03:50:00.170Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>部署 RabbitMQ、MongoDB 或其他服务的单节点，有时会将 bind_ip 之类的设置写作 127.0.0.1。然而在 Debian 系统这么操作可能就给自己挖了“坑”，不管你有没有遇到过 <code>host</code> 相关奇怪的部署问题，来看作者的一波填坑历程吧~</p>
<h3 id="Debian-的-默认-hostname-配置"><a href="#Debian-的-默认-hostname-配置" class="headerlink" title="Debian 的 默认 hostname 配置"></a>Debian 的 默认 hostname 配置</h3><p>在 Debian 系的 Linux 发行版中，<code>/etc/hosts</code> 中前两行默认配置如下，其中 <code>myhostname</code> 即 <code>/etc/hostname</code> 指定的本机名称，可通过 <code>hostname</code> 指令查看。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1 localhost</span><br><span class="line">127.0.1.1 myhostname</span><br></pre></td></tr></table></figure></p>
<p>第二行配置将本机 host 指向了 <code>127.0.1.1</code>，这又能对软件的安装造成什么影响呢？请看下面的例子。</p>
<a id="more"></a>
<h2 id="影响"><a href="#影响" class="headerlink" title="影响"></a>影响</h2><h3 id="MongoDB-举例"><a href="#MongoDB-举例" class="headerlink" title="MongoDB 举例"></a>MongoDB 举例</h3><p>我需要初始化一个 MongoDB 的单实例 Replset，并设置了 bindIP 为 127.0.0.1。这时调用 <code>rs.initiate()</code>，便会得到下列错误。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"ok"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="string">"errmsg"</span> : <span class="string">"No host described in new configuration 1 for replica set rs0 maps to this node"</span>,</span><br><span class="line">  <span class="string">"code"</span> : <span class="number">93</span>,</span><br><span class="line">  <span class="string">"codeName"</span> : <span class="string">"InvalidReplicaSetConfig"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>对于上面初始化 MongoDB 遇到的问题，其中一个解决方案是明确传递参数给 initiate 方法。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rs.initiate(&#123;<span class="attr">_id</span>:<span class="string">"yourReplSetName"</span>, <span class="attr">members</span>: [&#123;<span class="string">"_id"</span>:<span class="number">1</span>, <span class="string">"host"</span>:<span class="string">"yourHost:yourPort"</span>&#125;]&#125;)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>参见 <a href="https://stackoverflow.com/a/30850962" target="_blank" rel="noopener">https://stackoverflow.com/a/30850962</a></p>
</blockquote>
<p>而生效原因不难解释，由于在初始化过程未指定 <code>host</code> ， MongoDB 默认读取了本机的 <code>hostname</code> 作为 <code>yourHost</code> 参数值。但本机的 hostname 指向 ip 是 127.0.1.1，因此整个 <code>host</code> 参数实际变为 <code>127.0.1.1:27017</code>。而 bindIP 仅绑定了 127.0.0.1，我们并没有 127.0.1.1:27017 这个服务，通过 <code>netstat</code> 也可以证实。</p>
<p>这也解释了另一个解决方法：修改 <code>/etc/hosts</code> 文件中本机 hostname 对应的 ip 为 127.0.0.1。</p>
<blockquote>
<p>参见 <a href="https://stackoverflow.com/a/29055110" target="_blank" rel="noopener">https://stackoverflow.com/a/29055110</a></p>
</blockquote>
<p>解决方案可能还有很多，比如可以在 bindIp 中加上 127.0.1.1…</p>
<h3 id="RabbitMQ-举例"><a href="#RabbitMQ-举例" class="headerlink" title="RabbitMQ 举例"></a>RabbitMQ 举例</h3><p>同上，RabbitMQ 的部署也存在相似问题。因为 RabbitMQ 默认 nodename 是 rabbit@<code>hostname</code>。</p>
<p>在这个 <a href="https://github.com/zulip/zulip/issues/194" target="_blank" rel="noopener">issue</a> 中也看到 zulip 维护者 timabbott 的描述：</p>
<blockquote>
<p>We’re working on migrating to a system where we change the default rabbitmq<br>nodename from rabbit@<code>hostname</code> to <code>zulip@localhost</code>, for new installs,<br>which I think would eliminate this problem, since <code>localhost</code> should always<br>resolve to 127.0.0.1.</p>
</blockquote>
<h3 id="疑惑"><a href="#疑惑" class="headerlink" title="疑惑"></a>疑惑</h3><p>既然是普遍的问题，改 hostname 对应的 host 似乎成了最便捷的解决办法。既然如此，Debian 的默认 hostname 不写成 127.0.0.1 ？</p>
<p>这个 host 的主要作用是形成网络环路，并且 127.0.0.1 到 127.255.255.254 都是回环地址，选任一个 ip 都可以。至于为何选择 127.0.1.1，其实源于一个 bug，有兴趣可以从 debian 的 ref 追溯：<a href="https://www.debian.org/doc/manuals/debian-reference/ch05.en.html#_the_hostname_resolution" target="_blank" rel="noopener">https://www.debian.org/doc/manuals/debian-reference/ch05.en.html#_the_hostname_resolution</a></p>
<h2 id="FQDN"><a href="#FQDN" class="headerlink" title="FQDN"></a>FQDN</h2><p>改了这个 host 配置会导致其他异常吗？要解答这个疑问，需要先了解 FQDN。</p>
<p>引用<a href="https://onebitbug.me/2014/06/25/settings-fqdn-in-linux/" target="_blank" rel="noopener">《Linux下配置FQDN》</a>的描述。</p>
<blockquote>
<p>通常 hostname 在某个特定的范围内应该是唯一的，以免产生冲突，这个特定的范围通常用域（dnsdomain）表示。 而 fqdn（full qulified domain name）则应该在一个更大的范围内（比如全球）唯一， 通常 fqdn 是${hostname}.${dnsdomain}。 </p>
</blockquote>
<p>一旦修改了hostname到127.0.0.1，python 的 getfqdn() 将返回 <code>localhost</code> 而不是 <code>myhostname.dnsdomain</code>。结论：“这是为了最大程度的兼容各种工具的的getfqdn()实现”。</p>
<p>但如果你的项目不涉及相关内容，可以放心改动 /etc/hosts。顺便贴一个可以修改主机名对应的host为127.0.0.1”的脚本，可以加到服务的部署脚本中。<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i <span class="string">"s/127.0.1.1\s<span class="variable">$(hostname)</span>/127.0.0.1 <span class="variable">$(hostname)</span>/"</span> /etc/hosts</span><br></pre></td></tr></table></figure></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>虽然是个不起眼的问题，姑且串起来看还是有点意思的，<del>就这样又水了一篇博客</del>。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;部署 RabbitMQ、MongoDB 或其他服务的单节点，有时会将 bind_ip 之类的设置写作 127.0.0.1。然而在 Debian 系统这么操作可能就给自己挖了“坑”，不管你有没有遇到过 &lt;code&gt;host&lt;/code&gt; 相关奇怪的部署问题，来看作者的一波填坑历程吧~&lt;/p&gt;
&lt;h3 id=&quot;Debian-的-默认-hostname-配置&quot;&gt;&lt;a href=&quot;#Debian-的-默认-hostname-配置&quot; class=&quot;headerlink&quot; title=&quot;Debian 的 默认 hostname 配置&quot;&gt;&lt;/a&gt;Debian 的 默认 hostname 配置&lt;/h3&gt;&lt;p&gt;在 Debian 系的 Linux 发行版中，&lt;code&gt;/etc/hosts&lt;/code&gt; 中前两行默认配置如下，其中 &lt;code&gt;myhostname&lt;/code&gt; 即 &lt;code&gt;/etc/hostname&lt;/code&gt; 指定的本机名称，可通过 &lt;code&gt;hostname&lt;/code&gt; 指令查看。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;127.0.0.1 localhost&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;127.0.1.1 myhostname&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;第二行配置将本机 host 指向了 &lt;code&gt;127.0.1.1&lt;/code&gt;，这又能对软件的安装造成什么影响呢？请看下面的例子。&lt;/p&gt;
    
    </summary>
    
      <category term="Linux" scheme="https://claude-ray.github.io/categories/Linux/"/>
    
    
      <category term="Debian" scheme="https://claude-ray.github.io/tags/Debian/"/>
    
      <category term="hostname" scheme="https://claude-ray.github.io/tags/hostname/"/>
    
      <category term="fqdn" scheme="https://claude-ray.github.io/tags/fqdn/"/>
    
  </entry>
  
  <entry>
    <title>如何避免svn合并冲突</title>
    <link href="https://claude-ray.github.io/2019/01/29/ways-to-avoid-svn-conflict/"/>
    <id>https://claude-ray.github.io/2019/01/29/ways-to-avoid-svn-conflict/</id>
    <published>2019-01-29T14:13:36.000Z</published>
    <updated>2019-01-29T15:55:00.076Z</updated>
    
    <content type="html"><![CDATA[<p>svn 给笔者的一大印象就是非常容易产生冲突，特别是项目加入新人后，由于初期没有强硬地制定规范，导致后期合并代码时灾难连天。决定在此分享这些“亡羊补牢”的规则，也算是避免 svn 产生合并冲突的一点经验。</p>
<a id="more"></a>
<h2 id="一个简单的分支管理策略"><a href="#一个简单的分支管理策略" class="headerlink" title="一个简单的分支管理策略"></a>一个简单的分支管理策略</h2><p>正式分享 tips 前，先交代一下目前在用的 svn 管理策略，因为本文避免合并冲突的一些要点就是建立在此策略之上的。</p>
<p>类似于 git 的轻度规则，主要分为 dev、master、release 三种分支。</p>
<p>以 master 为核心，保存完整代码。release 则允许剔除未编译前端 js、测试用例、项目文档等运行环境不需要的文件，减轻发布体积。功能开发在各 dev 进行。因此 master 和 release 只需要处理代码合并。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">发布分支        主干       开发分支</span><br><span class="line"></span><br><span class="line">release1 &lt;-            &lt;- dev</span><br><span class="line">release2 &lt;-   master   &lt;- feature</span><br><span class="line">...      &lt;-            &lt;- ...</span><br></pre></td></tr></table></figure>
<h2 id="如何避免冲突"><a href="#如何避免冲突" class="headerlink" title="如何避免冲突"></a>如何避免冲突</h2><h3 id="1-编辑器装好-svn-相关插件。"><a href="#1-编辑器装好-svn-相关插件。" class="headerlink" title="1. 编辑器装好 svn 相关插件。"></a>1. 编辑器装好 svn 相关插件。</h3><p>不同于“装机必备”的 git ，很多编辑器没有自带 svn 的管理插件，需要用户自己安装。</p>
<p>尤其重要的功能是可以实时对比 diff，本地和远程仓库的差异一览无遗，不要再疑惑为什么本地顺畅线上崩盘了。</p>
<p>windows 开发环境可能需要配置 svn 环境变量，但不要偷懒，这点工作一劳永逸。</p>
<h3 id="2-细化提交。"><a href="#2-细化提交。" class="headerlink" title="2. 细化提交。"></a>2. 细化提交。</h3><p>当合并时，假如发现同一个提交下存在还未达到上线状态的变更，这种情况如果忽略合并某些代码，会导致该开发分支和 master 分支不再一致，为后继的开发者挖坑。</p>
<h3 id="3-开发分支也要规范-commit-log。"><a href="#3-开发分支也要规范-commit-log。" class="headerlink" title="3. 开发分支也要规范 commit log。"></a>3. 开发分支也要规范 commit log。</h3><p>尽管开发分支可能在功能完成后就被删除，依然要有意识地为各个 commit 打上前缀、标签。</p>
<p>假设某开发分支是多人协作，若 commit log 有合适的标签，可以增加合并时的检索效率，避免遗漏部分久远的提交。当然，除非业务关联性较大，放在一个分支方便做同时修改，最好还是分模块、分特性单独建开发分支。</p>
<h3 id="4-所有的合并操作，采取针对版本号的更改。"><a href="#4-所有的合并操作，采取针对版本号的更改。" class="headerlink" title="4. 所有的合并操作，采取针对版本号的更改。"></a>4. 所有的合并操作，采取针对版本号的更改。</h3><p>其实主要面向需要长期维护的开发分支，直接合并目录树会携带大量不稳定变更。</p>
<h3 id="5-对完整的分支执行合并。"><a href="#5-对完整的分支执行合并。" class="headerlink" title="5. 对完整的分支执行合并。"></a>5. 对完整的分支执行合并。</h3><p>对整个分支目录执行合并，而不是对单个文件、单个子目录做合并，否则结合第 2 点，这极容易埋下隐患。</p>
<h3 id="6-牢记发布分支-release-是-master-的快照。"><a href="#6-牢记发布分支-release-是-master-的快照。" class="headerlink" title="6. 牢记发布分支 release 是 master 的快照。"></a>6. 牢记发布分支 release 是 master 的快照。</h3><p>禁止跨过 master 在 release 直接提交代码。更危险的是在 release 提交的代码和 master 不一致，好在上次遇到这么做的被我及时制止了。XD</p>
<p>进一步要求，不要在 master 直接提交解决冲突以外的代码。</p>
<h3 id="7-定期把-master-的所有更改合并回开发分支。"><a href="#7-定期把-master-的所有更改合并回开发分支。" class="headerlink" title="7. 定期把 master 的所有更改合并回开发分支。"></a>7. 定期把 master 的所有更改合并回开发分支。</h3><p>尤其是涉及工具类、公共模块的更改。当开发分支维护不下去时，以 master 为基准重建开发分支。</p>
<h3 id="8-遇到-GUI-解决不了的冲突，命令行参数了解一下。"><a href="#8-遇到-GUI-解决不了的冲突，命令行参数了解一下。" class="headerlink" title="8. 遇到 GUI 解决不了的冲突，命令行参数了解一下。"></a>8. 遇到 GUI 解决不了的冲突，命令行参数了解一下。</h3><p>大杀器，说多了都是泪……</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>以上内容是笔者几乎照搬着对 git 的理解来总结的，可能并不成熟。不过经过了一年的实践，这些“规范”操作的确达到了避免冲突的目的，且远没有复杂过 git rebase 工具流。</p>
<p>制定规范是一回事，更应该要求团队成员继续加深对版本管理库的理解，思考分支合并存在的意义，养成更好的提交习惯。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;svn 给笔者的一大印象就是非常容易产生冲突，特别是项目加入新人后，由于初期没有强硬地制定规范，导致后期合并代码时灾难连天。决定在此分享这些“亡羊补牢”的规则，也算是避免 svn 产生合并冲突的一点经验。&lt;/p&gt;
    
    </summary>
    
      <category term="SVN" scheme="https://claude-ray.github.io/categories/SVN/"/>
    
    
      <category term="SVN" scheme="https://claude-ray.github.io/tags/SVN/"/>
    
  </entry>
  
  <entry>
    <title>Nginx改写$args未生效踩坑</title>
    <link href="https://claude-ray.github.io/2019/01/24/nginx-proxypass-args/"/>
    <id>https://claude-ray.github.io/2019/01/24/nginx-proxypass-args/</id>
    <published>2019-01-24T13:45:26.000Z</published>
    <updated>2019-01-24T16:22:28.028Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>原始需求是通过 nginx 在请求链接中增加一个固定参数 custom_param，方法很简单，在 location 中重设 <code>$args</code>。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># in location xxx</span></span><br><span class="line"><span class="built_in">set</span> <span class="variable">$args</span> <span class="variable">$args</span>&amp;custom_param=<span class="built_in">test</span>;</span><br><span class="line">proxy_pass http://remote_host;</span><br></pre></td></tr></table></figure>
<p>顺便说一下，即使链接中没有参数也不影响一般服务端解析，符号<code>?</code>会自动加上，如上例子 proxy_pass 后会路径将变成 <a href="http://remote_host/xxx?&amp;custom_param=test。" target="_blank" rel="noopener">http://remote_host/xxx?&amp;custom_param=test。</a></p>
<p>但问题是在服务器如此配置 nginx 后，custom_param 参数并没有如约发给 remote_host……</p>
<a id="more"></a>
<p>最终在 nginx change log 中找到了原因。</p>
<blockquote>
<p><a href="http://nginx.org/en/CHANGES" target="_blank" rel="noopener">http://nginx.org/en/CHANGES</a> Changes with nginx 1.7.1          27 May 2014</p>
<p>Bugfix: a “proxy_pass” directive without URI part might use original<br>  request after the $args variable was set.<br>  Thanks to Yichun Zhang.</p>
</blockquote>
<p>可以看出是nginx很早就修复的 bug，可以肯定到手的 nginx 版本太旧了，又试了版本 1.6.2 果然也存在问题，bug 存在的版本不多，相关资料很少。</p>
<p>在不升级 nginx 的情况下，修复方案是采用旧的参数附加方式<code>$uri$is_args$args</code>，如下</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> <span class="variable">$args</span> <span class="variable">$args</span>&amp;custom_param=<span class="built_in">test</span>;</span><br><span class="line">proxy_pass http://remote_host<span class="variable">$uri</span><span class="variable">$is_args</span><span class="variable">$args</span>;</span><br></pre></td></tr></table></figure>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>很多软件包的疑难杂症都可以试着查阅 change log，而且有些情况下检索历史变更比查 issue 更方便。之前<a href="https://claude-ray.github.io/2017/10/05/lodash-3-to-4/">《lodash3升级4踩坑》</a> 一文提到的 lodash 升级大版本导致 merge 用法变更，也是查 history 定位到了问题。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h2&gt;&lt;p&gt;原始需求是通过 nginx 在请求链接中增加一个固定参数 custom_param，方法很简单，在 location 中重设 &lt;code&gt;$args&lt;/code&gt;。&lt;/p&gt;
&lt;figure class=&quot;highlight sh&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# in location xxx&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;variable&quot;&gt;$args&lt;/span&gt; &lt;span class=&quot;variable&quot;&gt;$args&lt;/span&gt;&amp;amp;custom_param=&lt;span class=&quot;built_in&quot;&gt;test&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;proxy_pass http://remote_host;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;顺便说一下，即使链接中没有参数也不影响一般服务端解析，符号&lt;code&gt;?&lt;/code&gt;会自动加上，如上例子 proxy_pass 后会路径将变成 &lt;a href=&quot;http://remote_host/xxx?&amp;amp;custom_param=test。&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://remote_host/xxx?&amp;amp;custom_param=test。&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;但问题是在服务器如此配置 nginx 后，custom_param 参数并没有如约发给 remote_host……&lt;/p&gt;
    
    </summary>
    
      <category term="Nginx" scheme="https://claude-ray.github.io/categories/Nginx/"/>
    
    
      <category term="Nginx" scheme="https://claude-ray.github.io/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>Nginx的if使用须知</title>
    <link href="https://claude-ray.github.io/2019/01/09/nginx-ifisevil/"/>
    <id>https://claude-ray.github.io/2019/01/09/nginx-ifisevil/</id>
    <published>2019-01-09T14:42:14.000Z</published>
    <updated>2019-01-09T16:49:29.027Z</updated>
    
    <content type="html"><![CDATA[<p>被 nginx 官方自我批判的 if 语句，《<a href="https://www.nginx.com/resources/wiki/start/topics/depth/ifisevil/" target="_blank" rel="noopener">If Is Evil</a>》——这应该成为每位开发者初次使用 nginx 的 if 之前必读的文章。</p>
<p>即使一年前就开始用 nginx 和 if 的组合做跳转，但涉及的功能太简单，没能见识到它的真面目。当我在多个 if 内处理 proxy_pass 时，噩梦就降临了。<br><a id="more"></a></p>
<h1 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h1><p>if 本身是 rewrite 模块的一部分，然而在非 rewrite 环境下也可以用，显然这是错误的用法，进而引发很多出乎意料的问题。</p>
<h1 id="How"><a href="#How" class="headerlink" title="How"></a>How</h1><p>最直观的还是来看代码，下面引用 If Is Evil 的 <a href="https://www.nginx.com/resources/wiki/start/topics/depth/ifisevil/#examples" target="_blank" rel="noopener">Example 部分</a>，用 30 秒即可浏览大部分 evil 场景。</p>
<ol>
<li><p>只有X-Second会被设置</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">location</span> /only-one-if &#123;</span><br><span class="line">    <span class="attribute">set</span> <span class="variable">$true</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">if</span> (<span class="variable">$true</span>) &#123;</span><br><span class="line">        <span class="attribute">add_header</span> X-First <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">if</span> (<span class="variable">$true</span>) &#123;</span><br><span class="line">        <span class="attribute">add_header</span> X-Second <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">return</span> <span class="number">204</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>proxy_pass 不会生效</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">location</span> /proxy-pass-uri &#123;</span><br><span class="line">    <span class="attribute">proxy_pass</span> http://127.0.0.1:8080/;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">set</span> <span class="variable">$true</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">if</span> (<span class="variable">$true</span>) &#123;</span><br><span class="line">        <span class="comment"># nothing</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>try_files 不会生效</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">location</span> /if-try-files &#123;</span><br><span class="line">     <span class="attribute">try_files</span>  /file  <span class="variable">@fallback</span>;</span><br><span class="line"></span><br><span class="line">     <span class="attribute">set</span> <span class="variable">$true</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">     <span class="attribute">if</span> (<span class="variable">$true</span>) &#123;</span><br><span class="line">         <span class="comment"># nothing</span></span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>nginx 将发出段错误信号 SIGSEGV</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">location</span> /crash &#123;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">set</span> <span class="variable">$true</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">if</span> (<span class="variable">$true</span>) &#123;</span><br><span class="line">        <span class="comment"># fastcgi_pass here</span></span><br><span class="line">        <span class="attribute">fastcgi_pass</span>  <span class="number">127.0.0.1:9000</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">if</span> (<span class="variable">$true</span>) &#123;</span><br><span class="line">        <span class="comment"># no handler here</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>alias 无法正确地被继承到由 if 创建的隐式嵌套 location 中</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">location</span> <span class="regexp">~* ^/if-and-alias/(?&lt;file&gt;.*)</span> &#123;</span><br><span class="line">    <span class="attribute">alias</span> /tmp/<span class="variable">$file</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">set</span> <span class="variable">$true</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">if</span> (<span class="variable">$true</span>) &#123;</span><br><span class="line">        <span class="comment"># nothing</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="如何避免"><a href="#如何避免" class="headerlink" title="如何避免"></a>如何避免</h1><p>既然 if 如此之坑，最好的办法就是乖乖禁用 if，但拗不过诸位喜欢折腾的灵魂，特殊场景还是可以用的。下面列举最常见的避坑方案。</p>
<h2 id="官方认可的两种用法"><a href="#官方认可的两种用法" class="headerlink" title="官方认可的两种用法"></a>官方认可的两种用法</h2><p>再怎么说，if 就是为 rewrite 服务的，如果有 bug 早被封杀了。<br><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#The only 100% safe things which may be done inside if in a location context are:</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">return</span> ...;</span><br><span class="line"><span class="attribute">rewrite</span> ... <span class="literal">last</span>;</span><br></pre></td></tr></table></figure></p>
<h2 id="proxy-pass-中及时-break"><a href="#proxy-pass-中及时-break" class="headerlink" title="proxy_pass 中及时 break"></a>proxy_pass 中及时 break</h2><p>当处理各种跳转逻辑时，假设你不期望因为多传了个等于 “hi” 的参数 parma2，就导致 <code>param1 ~ &quot;hello&quot;</code> 的跳转失败，那么应该在合适的地方增加 break。<br><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">location</span> /proxy-pass-uri &#123;</span><br><span class="line">    <span class="attribute">set</span> <span class="variable">$true</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">if</span> (<span class="variable">$arg_param1</span> <span class="regexp">~ "hello")</span> &#123;</span><br><span class="line">      <span class="attribute">proxy_pass</span> http://127.0.0.1:8080/;</span><br><span class="line">      <span class="comment"># 这里的break将阻止下面if的执行</span></span><br><span class="line">      break;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">if</span> (<span class="variable">$arg_param2</span> <span class="regexp">~ "hi")</span> &#123;</span><br><span class="line">      <span class="comment"># anything</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">proxy_pass</span> http://127.0.0.1:8082/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>此外，也可以通过调整 if 的顺序来规避风险，但是容错率比 break 低了很多</p>
</blockquote>
<h2 id="使用-lua"><a href="#使用-lua" class="headerlink" title="使用 lua"></a>使用 lua</h2><blockquote>
<p><a href="https://github.com/openresty/lua-nginx-module" target="_blank" rel="noopener">https://github.com/openresty/lua-nginx-module</a></p>
</blockquote>
<p>具体来说，通过安装 lua 和 lua-nginx-module( 或 OpenResty ) 来增强 nginx 的逻辑处理，可以称为目前最流行有效的处理方案。lua 扩展带来的好处远不止 if 语句的避坑，例如带来方便地读取 POST 请求体的内容等便利操作。网上资料齐全，这里不多赘述。</p>
<h2 id="使用-njs"><a href="#使用-njs" class="headerlink" title="使用 njs"></a>使用 njs</h2><blockquote>
<p><a href="http://nginx.org/en/docs/njs/index.html" target="_blank" rel="noopener">http://nginx.org/en/docs/njs/index.html</a></p>
</blockquote>
<p>nginScript (njs) 是 nginx 在 2015 发布的 javascript 配置方案。类似于 lua-nginx-module，它也需要安装相关依赖模块。但有官方做后盾的 njs，比起 lua 要更为轻量，不需要完整的语言运行环境。并且针对 nginx 环境进行设计，理论上有更高的优化空间。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>到此，坑点和避坑的方法都阐明了，如果还想了解 nginx if 背后的机制，或有其他疑问，请继续探寻《If Is Evil》原文吧！</p>
<p>再次附上传送门：</p>
<blockquote>
<p><a href="https://www.nginx.com/resources/wiki/start/topics/depth/ifisevil/" target="_blank" rel="noopener">https://www.nginx.com/resources/wiki/start/topics/depth/ifisevil/</a></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;被 nginx 官方自我批判的 if 语句，《&lt;a href=&quot;https://www.nginx.com/resources/wiki/start/topics/depth/ifisevil/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;If Is Evil&lt;/a&gt;》——这应该成为每位开发者初次使用 nginx 的 if 之前必读的文章。&lt;/p&gt;
&lt;p&gt;即使一年前就开始用 nginx 和 if 的组合做跳转，但涉及的功能太简单，没能见识到它的真面目。当我在多个 if 内处理 proxy_pass 时，噩梦就降临了。&lt;br&gt;
    
    </summary>
    
      <category term="Nginx" scheme="https://claude-ray.github.io/categories/Nginx/"/>
    
    
      <category term="Nginx" scheme="https://claude-ray.github.io/tags/Nginx/"/>
    
      <category term="If Is Evil" scheme="https://claude-ray.github.io/tags/If-Is-Evil/"/>
    
  </entry>
  
  <entry>
    <title>crontab 中使用 pm2</title>
    <link href="https://claude-ray.github.io/2019/01/03/pm2-crontab/"/>
    <id>https://claude-ray.github.io/2019/01/03/pm2-crontab/</id>
    <published>2019-01-03T13:56:48.000Z</published>
    <updated>2019-01-03T15:37:16.453Z</updated>
    
    <content type="html"><![CDATA[<p>本篇不是讲如何处理代码内的定时任务，而是聊聊怎么借助 crontab 等工具，定时操作 pm2 (指令)。例如，定时重启 pm2 中的进程、定时执行 pm2 save 保存运行状态，等等。<br><a id="more"></a></p>
<h1 id="重启进程"><a href="#重启进程" class="headerlink" title="重启进程"></a>重启进程</h1><p><code>pm2 --help</code> 可以看到 pm2 自带 cron 功能，但功能仅限于重启进程。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Usage: pm2 [cmd] app</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line"></span><br><span class="line">-c --cron &lt;cron_pattern&gt;     restart a running process based on a cron pattern</span><br></pre></td></tr></table></figure>
<h1 id="执行指令"><a href="#执行指令" class="headerlink" title="执行指令"></a>执行指令</h1><p>执行指令包括重启 pm2 内的进程，并且可以定时调用 pm2 做任何它支持的事。这种情况下，使用系统层面的 <code>crontab</code> 就对啦。</p>
<p>需要注意的是，pm2 在 crontab 中的运行 PATH 和 在 命令行 shell 中直接执行并不一样，因此会报 <code>pm2: command not found</code> 之类的错。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 错误示范</span></span><br><span class="line">*/1 * * * * pm2 flush &gt; /var/<span class="built_in">log</span>/pm2flush.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure>
<p>解决方法是在使用pm2的脚本中指定环境变量，参考<code>which pm2</code>，找出pm2的bin路径。</p>
<p>一般是通过<code>npm i pm2 -g</code>全局安装，环境变量是<code>/urs/local/node/bin</code>。如果你使用nvm，那可能是<code>/home/yourname/.nvm/versions/node/vX.X.X/bin</code>。</p>
<h1 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h1><h2 id="pm2-flush"><a href="#pm2-flush" class="headerlink" title="pm2 flush"></a>pm2 flush</h2><p>例如我们要定时清除 pm2 的 log 文件，节省磁盘空间，可以使用 pm2 自带的 flush 命令。</p>
<h2 id="直接执行"><a href="#直接执行" class="headerlink" title="直接执行"></a>直接执行</h2><p>一种是直接在定时器执行 pm2 flush</p>
<blockquote>
<p>PATH 的指定要结合具体情况，常见的做法是命令行 <code>echo $PATH</code>，把输出内容补到指令的 PATH 中</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SHELL=/bin/sh</span><br><span class="line">PATH=/usr/<span class="built_in">local</span>/sbin:/usr/<span class="built_in">local</span>/bin:/sbin:/bin:/usr/sbin:/usr/bin:/usr/<span class="built_in">local</span>/node/bin</span><br><span class="line"></span><br><span class="line">*/1 * * * * pm2 flush &gt; /var/<span class="built_in">log</span>/pm2flush.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure>
<h2 id="间接执行"><a href="#间接执行" class="headerlink" title="间接执行"></a>间接执行</h2><p>另一种是定时调用任务脚本，通过脚本间接执行 pm2 flush，这样方便我们同时做其他处理，如删除日志前先打包备份。</p>
<p>在 crontab 中，内容如下<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SHELL=/bin/sh</span><br><span class="line">PATH=/usr/<span class="built_in">local</span>/sbin:/usr/<span class="built_in">local</span>/bin:/sbin:/bin:/usr/sbin:/usr/bin:/usr/<span class="built_in">local</span>/node/bin</span><br><span class="line"></span><br><span class="line">*/1 * * * * sh /home/root/pm2flush.sh &gt; /var/<span class="built_in">log</span>/pm2flush.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure></p>
<p>再来看它执行的 <code>pm2flush.sh</code> 文件<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果crontab中不指定node bin的PATH，也可以在这里通过如下方式指定</span></span><br><span class="line"><span class="comment"># PATH=$PATH:/usr/local/node/bin</span></span><br><span class="line">pm2 flush</span><br></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇不是讲如何处理代码内的定时任务，而是聊聊怎么借助 crontab 等工具，定时操作 pm2 (指令)。例如，定时重启 pm2 中的进程、定时执行 pm2 save 保存运行状态，等等。&lt;br&gt;
    
    </summary>
    
      <category term="Linux" scheme="https://claude-ray.github.io/categories/Linux/"/>
    
    
      <category term="pm2" scheme="https://claude-ray.github.io/tags/pm2/"/>
    
      <category term="crontab" scheme="https://claude-ray.github.io/tags/crontab/"/>
    
  </entry>
  
  <entry>
    <title>PM2 cluster + log4js？并不理想的组合</title>
    <link href="https://claude-ray.github.io/2018/12/21/pm2-cluster-log4js/"/>
    <id>https://claude-ray.github.io/2018/12/21/pm2-cluster-log4js/</id>
    <published>2018-12-21T12:49:03.000Z</published>
    <updated>2018-12-22T05:53:09.215Z</updated>
    
    <content type="html"><![CDATA[<h1 id="log4js-和-cluster"><a href="#log4js-和-cluster" class="headerlink" title="log4js 和 cluster"></a>log4js 和 cluster</h1><h2 id="写策略"><a href="#写策略" class="headerlink" title="写策略"></a>写策略</h2><p>node cluster 多个进程同时写一个文件是不安全的，通常会只选择一个 master 进程负责写入，其他 worker 进程则将数据传输到 master。</p>
<p>log4js 的写策略正是如此，但默认只适用于 node 原生的 cluster 模式，然而通过 pm2 启动的进程都是 worker。</p>
<p>官方提供的方案是安装 <code>pm2-intercom</code>，并在代码配置 log4js 时打开 <code>pm2: true</code> 选项，其原理也是选出一个负责写文件的主进程。<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pm2 install pm2-intercom</span><br></pre></td></tr></table></figure></p>
<h2 id="选举-master"><a href="#选举-master" class="headerlink" title="选举 master"></a>选举 master</h2><p>log4js 选择主进程的<a href="https://github.com/log4js-node/log4js-node/blob/master/lib/clustering.js#L13" target="_blank" rel="noopener">策略</a>：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> isPM2Master = <span class="function"><span class="params">()</span> =&gt;</span> pm2 &amp;&amp; process.env[pm2InstanceVar] === <span class="string">'0'</span>;</span><br><span class="line"><span class="keyword">const</span> isMaster = <span class="function"><span class="params">()</span> =&gt;</span> disabled || cluster.isMaster || isPM2Master();</span><br></pre></td></tr></table></figure></p>
<p>其中 disabled 是 log4js 的 disableClustering 选项，设置为 true 后，所有进程都将作为 master 进而拥有写文件的权限，这并没有解决安全问题。它存在的价值后面再说。</p>
<p>每个 pm2 启动的进程都有唯一的 process.env.NODE_APP_INSTANCE 标识，<code>process.env.NODE_APP_INSTANCE === &#39;0&#39;</code> 是常见的选择主从方式。多进程同时记录日志时，也可以用此方式指定唯一的进程负责写文件，避免同时写文件造成的冲突。此外 pm2 支持通过重命名 <code>instance_var</code> 来改变 process.env 的标记名，目的是解决和 <code>node-config</code> 包共用导致的异常。</p>
<blockquote>
<p><a href="http://pm2.keymetrics.io/docs/usage/environment/#specific-environment-variables" target="_blank" rel="noopener">关于 NODE_APP_INSTANCE 的 pm2 官方说明</a></p>
</blockquote>
<h2 id="问题多多的-pm2-intercom-方案"><a href="#问题多多的-pm2-intercom-方案" class="headerlink" title="问题多多的 pm2-intercom 方案"></a>问题多多的 pm2-intercom 方案</h2><p>当下 pm2 的版本是 3.2.x，而 <code>pm2-intercom</code> 在 pm2 2.x 版本就已经存在异常了，重复日志甚至丢失日志，或在开发环境运行正常，到了线上莫名失败。更严重的是，当一个 pm2 box 内运行多个 cluster 模式启动的应用时，日志记录会变得混乱，各应用的日志都乱入了最早启动的应用的日志文件中。</p>
<p>log4js 的维护者 nomiddlename 也在 issue 中表示 pm2-intercom 存在着古怪的问题。</p>
<blockquote>
<p><a href="https://github.com/log4js-node/log4js-node/issues/265#issuecomment-359126674" target="_blank" rel="noopener">log4js doesn’t work with PM2 cluster mode #265</a></p>
<p>pm2-intercom has always seemed a bit dodgy - for some people it never works at all anyway. It didn’t need to use git clone when I installed it. Best plan might be to use the disableClustering option in your log4js config, log to stdout and let pm2 handle the files as it normally would.</p>
</blockquote>
<h2 id="option-disableClustering-不是银弹"><a href="#option-disableClustering-不是银弹" class="headerlink" title="option.disableClustering 不是银弹"></a>option.disableClustering 不是银弹</h2><p>上面再次提到 <code>disableClustering</code> 选项，不错，pm2-intercom 异常的场景可以拿它救场，但要注意它本身不适用于直接写文件，每个进程都被赋予了 master 权限，会再次引发开篇的冲突问题。官方文档也明确警示：<code>Be careful if you’re logging to files</code>。</p>
<h1 id="pm2-intercom-粗解"><a href="#pm2-intercom-粗解" class="headerlink" title="pm2-intercom 粗解"></a>pm2-intercom 粗解</h1><p>这个模块是简易的 IPC，借助 <code>process.send</code> 方法，将多个进程的数据包统一发送至 pm2 中编号为 0 的 pm2-intercom 进程，此进程再将收到的消息推送至项目进程中的一个。</p>
<p>在log4js的使用场景，表现为各自进程的日志首先发送到 pm2-intercom，由 pm2-intercom 分发到全部进程，但只有 log4js isMaster 才会写文件。</p>
<p>分发代码如下<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span>(<span class="params">packet</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">async</span>.forEachLimit(process_list, <span class="number">3</span>, <span class="function"><span class="keyword">function</span>(<span class="params">proc, next</span>) </span>&#123;</span><br><span class="line">    sendDataToProcessId(proc.pm_id, packet);</span><br><span class="line">  &#125;, <span class="function"><span class="keyword">function</span>(<span class="params">err</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (err) <span class="built_in">console</span>.error(err);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>如果想在多进程模式下记录日志到同一个文件，log4js + PM2 显然不是完美的组合。winston 也有人反馈丢日志的<a href="https://github.com/winstonjs/winston/issues/1466" target="_blank" rel="noopener">问题</a>，但没有得到官方回复前，仍需要验证。</p>
<p>如果想安全记录日志，还是得分多个文件，或脱离 pm2，像 egg 一样在框架层面自行 cluster。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><p><a href="https://log4js-node.github.io/log4js-node/clustering.html" target="_blank" rel="noopener">Clustering / Multi-process Logging</a></p>
</li>
<li><p><a href="https://www.npmjs.com/package/lj-log4js-pm2intercom" target="_blank" rel="noopener">to-fix-pm2-intercom-in-pm2-2x</a></p>
</li>
<li><p><a href="https://juejin.im/post/5b7d0e20f265da43231f00d4" target="_blank" rel="noopener">再说打日志你不会，pm2 + log4js，你值得拥有</a></p>
</li>
<li><p><a href="https://www.jianshu.com/p/20fcb3672723" target="_blank" rel="noopener">探索 PM2 Cluster 模式下 Log4js 日志丢失</a></p>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;log4js-和-cluster&quot;&gt;&lt;a href=&quot;#log4js-和-cluster&quot; class=&quot;headerlink&quot; title=&quot;log4js 和 cluster&quot;&gt;&lt;/a&gt;log4js 和 cluster&lt;/h1&gt;&lt;h2 id=&quot;写策略&quot;&gt;&lt;a h
    
    </summary>
    
      <category term="Node.js" scheme="https://claude-ray.github.io/categories/Node-js/"/>
    
    
      <category term="Node.js" scheme="https://claude-ray.github.io/tags/Node-js/"/>
    
      <category term="pm2" scheme="https://claude-ray.github.io/tags/pm2/"/>
    
      <category term="log4js" scheme="https://claude-ray.github.io/tags/log4js/"/>
    
      <category term="pm2-intercom" scheme="https://claude-ray.github.io/tags/pm2-intercom/"/>
    
  </entry>
  
  <entry>
    <title>iptables不会主动断开已有连接</title>
    <link href="https://claude-ray.github.io/2018/12/15/iptables-wont-block-established-connections/"/>
    <id>https://claude-ray.github.io/2018/12/15/iptables-wont-block-established-connections/</id>
    <published>2018-12-15T10:48:24.000Z</published>
    <updated>2018-12-15T10:53:28.715Z</updated>
    
    <content type="html"><![CDATA[<h2 id="What"><a href="#What" class="headerlink" title="What?"></a>What?</h2><p>源于一次mongodb超时问题查证。具体表现是服务响应异常缓慢，mongodb查询甚至报出<code>cursor id not found</code>。</p>
<p>在排除网络连通性和主机自身因素后，继续回归mongo连接异常的点上，直到发现mongo集群的iptables没有开放mongo端口，开墙后一切恢复正常。</p>
<h2 id="Why"><a href="#Why" class="headerlink" title="Why?"></a>Why?</h2><p>据查证，防火墙关闭mongo端口已经有一段时间了，为什么很久之后才出现连接不上的问题？</p>
<p>因为iptables不会主动断开已经建立的连接，这不是<code>packet filter</code>的职责所在。</p>
<p>但它依然有办法阻止现有连接的数据包（iptables的过滤基于数据包而非连接）。只不过，通常我们配置防火墙时都会加上一句：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT</span><br></pre></td></tr></table></figure></p>
<p>这就导致了已建立的连接可以无障碍地继续传输。</p>
<p>正因如此，mongodb的连接早已建立，被iptables置于ESTABLISHED中，所以不会受到仅ip规则更新的影响。当业务进程重启、网络波动等情况导致旧的连接断开时，将无法重新连接。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://linux.die.net/man/8/iptables" target="_blank" rel="noopener">https://linux.die.net/man/8/iptables</a></p>
<p><a href="https://serverfault.com/questions/785691/how-does-one-close-all-existing-tcp-connections-on-some-ports-using-iptables" target="_blank" rel="noopener">https://serverfault.com/questions/785691/how-does-one-close-all-existing-tcp-connections-on-some-ports-using-iptables</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;What&quot;&gt;&lt;a href=&quot;#What&quot; class=&quot;headerlink&quot; title=&quot;What?&quot;&gt;&lt;/a&gt;What?&lt;/h2&gt;&lt;p&gt;源于一次mongodb超时问题查证。具体表现是服务响应异常缓慢，mongodb查询甚至报出&lt;code&gt;cursor id
    
    </summary>
    
      <category term="Linux" scheme="https://claude-ray.github.io/categories/Linux/"/>
    
    
      <category term="iptables" scheme="https://claude-ray.github.io/tags/iptables/"/>
    
      <category term="Linux" scheme="https://claude-ray.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>总结node处理GBK编码</title>
    <link href="https://claude-ray.github.io/2018/12/12/node-gbk-sum/"/>
    <id>https://claude-ray.github.io/2018/12/12/node-gbk-sum/</id>
    <published>2018-12-12T14:49:00.000Z</published>
    <updated>2018-12-18T16:17:00.896Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>Node内部不支持直接操作GBK字符串，而实际也并不需要如此。</p>
<p>总的原则是，gbk的逻辑仅保留在输入和输出，内部处理一律使用utf8。编码转换主要基于<code>iconv-lite</code>库。</p>
<p>总结已经写在了前头，下面再列举几种http服务中常见的处理场景。</p>
<h1 id="常见场景"><a href="#常见场景" class="headerlink" title="常见场景"></a>常见场景</h1><h2 id="请求返回值"><a href="#请求返回值" class="headerlink" title="请求返回值"></a>请求返回值</h2><p>最常用且容易处理，通常我们使用<code>request</code>发起http请求，options中设置<code>encoding: null</code>，这样返回的res.body为buffer，再对buffer进行解码<code>iconv.decode(res.body, encoding)</code>。</p>
<blockquote>
<p>引用：<a href="https://claude-ray.github.io/2018/02/26/request%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98/#%E7%BC%96%E7%A0%81">request返回值中文乱码问题</a></p>
</blockquote>
<h2 id="请求参数"><a href="#请求参数" class="headerlink" title="请求参数"></a>请求参数</h2><p>这里直接用<code>iconv-lite</code>处理略显复杂，建议上<a href="https://github.com/node-modules/urlencode" target="_blank" rel="noopener">urlencode</a>。</p>
<p>post请求时stringify整个body对象，用options.form提交。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urlencode.stringify(body, &#123;<span class="attr">charset</span>: <span class="string">'gbk'</span>&#125;);</span><br></pre></td></tr></table></figure></p>
<p>querystring则stringify后再拼到url中。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urlencode.stringify(qs, &#123;<span class="attr">charset</span>: <span class="string">'gbk'</span>&#125;);</span><br></pre></td></tr></table></figure></p>
<h2 id="接口返回值"><a href="#接口返回值" class="headerlink" title="接口返回值"></a>接口返回值</h2><p>以koa举例，返回值先使用<code>iconv-lite</code>转为gbk Buffer，随后设置响应头的content-type。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ctx.body = iconv.encode(<span class="string">'你好'</span>, <span class="string">'gbk'</span>);</span><br><span class="line">ctx.type = <span class="string">'text/plain; charset=gbk'</span>;</span><br></pre></td></tr></table></figure></p>
<h2 id="接口参数"><a href="#接口参数" class="headerlink" title="接口参数"></a>接口参数</h2><p>同样以koa举例，结合<code>koa-bodyparser</code>，一般http method的原始参数分布在ctx.request.rawBody和ctx.request.querystring中，使用<code>urlencode.parse</code>解析。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">urlencode.parse(ctx.request.rawBody, &#123;<span class="attr">charset</span>: <span class="string">'gbk'</span>&#125;);</span><br><span class="line">urlencode.parse(ctx.request.querystring, &#123;<span class="attr">charset</span>: <span class="string">'gbk'</span>&#125;);</span><br></pre></td></tr></table></figure></p>
<p>特别地，当请求格式为multipart或json时需要结合具体情况具体分析。</p>
<p>例如，使用<code>busboy</code>等multipart解析库会将请求body挂在<code>ctx.request.body</code>上，规范的请求方式是会对字符进行url encode的，这时可以按gbk编码对字段decode（由于不能直接url decode，实际处理方法为转hex后再经buffer解码）。</p>
<p>如果请求参数是经过binary处理的，则binary decode。</p>
<p>综上，处理姿势大致如下。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">lodash.mapValues(ctx.request.body, value =&gt; &#123;</span><br><span class="line">  <span class="keyword">if</span> (!value) <span class="keyword">return</span> value;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> buff = <span class="regexp">/^(%\w&#123;2&#125;)+$/</span>.test(value)</span><br><span class="line">    ? Buffer.from(value.replace(<span class="regexp">/%/g</span>, <span class="string">''</span>), <span class="string">'hex'</span>)</span><br><span class="line">    : Buffer.from(value, <span class="string">'binary'</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> iconv.decode(buff, <span class="string">'gbk'</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<p>想兼容更多情况是比较复杂的，即使做基础服务也不必包容所有不规范的传值，大可以拒绝解析，因此按需调整即可。</p>
<p>如果能约定使用十六进制传参更好，处理hex就不需要在参数获取上额外操作了。可惜一般用到gbk的场景都是难以变更的、需要兼容的，否则肯定是让调用方改传utf8，皆大欢喜。</p>
<h2 id="读写文件"><a href="#读写文件" class="headerlink" title="读写文件"></a>读写文件</h2><p>默认方式（<code>encoding: null</code>）就是操作buffer，iconv转换无压力。</p>
<p>读：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> buff = fs.readFileSync(<span class="string">'test.txt'</span>);</span><br><span class="line"><span class="built_in">console</span>.log(iconv.decode(buff, <span class="string">'gbk'</span>));</span><br></pre></td></tr></table></figure></p>
<p>写：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> buff = iconv.encode(<span class="string">'你好'</span>, <span class="string">'gbk'</span>);</span><br><span class="line">fs.writeFileSync(<span class="string">'test.txt'</span>, buff);</span><br></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;Node内部不支持直接操作GBK字符串，而实际也并不需要如此。&lt;/p&gt;
&lt;p&gt;总的原则是，gbk的逻辑仅保留在输入和输出，内部处理一律使用u
    
    </summary>
    
      <category term="Node.js" scheme="https://claude-ray.github.io/categories/Node-js/"/>
    
    
      <category term="Node.js" scheme="https://claude-ray.github.io/tags/Node-js/"/>
    
      <category term="String" scheme="https://claude-ray.github.io/tags/String/"/>
    
      <category term="GBK编码" scheme="https://claude-ray.github.io/tags/GBK%E7%BC%96%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu配置ss-local客户端</title>
    <link href="https://claude-ray.github.io/2018/12/01/ss-local/"/>
    <id>https://claude-ray.github.io/2018/12/01/ss-local/</id>
    <published>2018-12-01T14:03:28.000Z</published>
    <updated>2019-05-15T04:37:02.099Z</updated>
    
    <content type="html"><![CDATA[<p>ss-local是<a href="https://github.com/shadowsocks/shadowsocks-libev" target="_blank" rel="noopener">shadowsocks-libev</a>提供的客户端工具，若想正常使用需先准备一台机器部署shadowsocks服务端以作为代理。</p>
<h2 id="一、安装准备"><a href="#一、安装准备" class="headerlink" title="一、安装准备"></a>一、安装准备</h2><p>Ubuntu 16以上直接用apt安装，其他发行版可以查阅文档<a href="https://github.com/shadowsocks/shadowsocks-libev#installation" target="_blank" rel="noopener">https://github.com/shadowsocks/shadowsocks-libev#installation</a><br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install shadowsocks-libev</span><br></pre></td></tr></table></figure></p>
<h2 id="二、编辑配置文件"><a href="#二、编辑配置文件" class="headerlink" title="二、编辑配置文件"></a>二、编辑配置文件</h2><h3 id="配置代理服地址"><a href="#配置代理服地址" class="headerlink" title="配置代理服地址"></a>配置代理服地址</h3><p>参考config.json修改local.json，填写代理服务器的地址。<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /etc/shadowsocks-libev/config.json /etc/shadowsocks-libev/local.json</span><br><span class="line">sudo vi /etc/shadowsocks-libev/local.json</span><br></pre></td></tr></table></figure></p>
<p>建议<code>local_port</code>不要使用默认的1080，例如改为1081。主要是避免和ss-server（在安装后默认作为<code>shadowsocks-libev.service</code>启动）抢占端口，或者选择手动停掉ss-server。<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"server"</span>: <span class="string">"代理服地址"</span>,</span><br><span class="line">  <span class="attr">"server_port"</span>: <span class="string">"代理服端口"</span>,</span><br><span class="line">  <span class="attr">"local_port"</span>: <span class="number">1081</span>,</span><br><span class="line">  <span class="attr">"password"</span>: <span class="string">"代理服密码"</span>,</span><br><span class="line">  <span class="attr">"timeout"</span>: <span class="number">60</span>,</span><br><span class="line">  <span class="attr">"method"</span>: <span class="string">"chacha20-ietf-poly1305"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="配置systemd-service"><a href="#配置systemd-service" class="headerlink" title="配置systemd service"></a>配置systemd service</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /lib/systemd/system/shadowsocks-libev-local@.service</span><br></pre></td></tr></table></figure>
<p>替换其中ExecStart的配置路径<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ExecStart=/usr/bin/ss-local -c /etc/shadowsocks-libev/local.json</span><br></pre></td></tr></table></figure></p>
<h2 id="三、启动服务"><a href="#三、启动服务" class="headerlink" title="三、启动服务"></a>三、启动服务</h2><p>使用systemctl或service管理服务<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#启动</span></span><br><span class="line">sudo systemctl start shadowsocks-libev-local@.</span><br><span class="line"><span class="comment">#或 $ sudo service shadowsocks-libev-local@.service start</span></span><br><span class="line"><span class="comment">#查看运行情况</span></span><br><span class="line">sudo systemctl status shadowsocks-libev-local@.</span><br><span class="line"><span class="comment">#配置开机自启</span></span><br><span class="line">sudo systemctl <span class="built_in">enable</span> shadowsocks-libev-local@.</span><br></pre></td></tr></table></figure></p>
<h2 id="四、配置PAC文件"><a href="#四、配置PAC文件" class="headerlink" title="四、配置PAC文件"></a>四、配置PAC文件</h2><p>PAC的语法是js，规则非常简单。核心点是实现<code>FindProxyForURL</code>函数，判断当前域名是否使用代理，不需要代理的域名直接返回<code>DIRECT</code>。</p>
<p>因此内容自己实现就可以，但不支持es6及以上特定，这里参考<a href="https://github.com/JinnLynn/genpac" target="_blank" rel="noopener">genpac</a>加上endsWith的polyfill。</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 端口号按之前配置local.json的local_port来填写，默认1080</span></span><br><span class="line"><span class="keyword">var</span> proxy = <span class="string">'SOCKS5 127.0.0.1:1081'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 走代理的host</span></span><br><span class="line"><span class="keyword">var</span> hosts = [</span><br><span class="line">  <span class="string">'evernote.com'</span></span><br><span class="line">];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">FindProxyForURL</span>(<span class="params">url, host</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; hosts.length; i++) &#123;</span><br><span class="line">    <span class="keyword">if</span> (host.endsWith(hosts[i])) <span class="keyword">return</span> proxy;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="string">'DIRECT'</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * REF:</span></span><br><span class="line"><span class="comment"> * genpac 2.1.0</span></span><br><span class="line"><span class="comment"> * https://github.com/JinnLynn/genpac</span></span><br><span class="line"><span class="comment"> * https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/endsWith</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (!<span class="built_in">String</span>.prototype.endsWith) &#123;</span><br><span class="line">  <span class="built_in">String</span>.prototype.endsWith = <span class="function"><span class="keyword">function</span>(<span class="params">searchString, position</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> subjectString = <span class="keyword">this</span>.toString();</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">typeof</span> position !== <span class="string">'number'</span> || !<span class="built_in">isFinite</span>(position) || <span class="built_in">Math</span>.floor(position) !== position || position &gt; subjectString.length) &#123;</span><br><span class="line">        position = subjectString.length;</span><br><span class="line">    &#125;</span><br><span class="line">    position -= searchString.length;</span><br><span class="line">    <span class="keyword">var</span> lastIndex = subjectString.indexOf(searchString, position);</span><br><span class="line">    <span class="keyword">return</span> lastIndex !== <span class="number">-1</span> &amp;&amp; lastIndex === position;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="五、配置系统代理"><a href="#五、配置系统代理" class="headerlink" title="五、配置系统代理"></a>五、配置系统代理</h2><p>这一步可以通过export来设置，但没找到automatic的配置方法，干脆用系统自带的proxy来处理。按如下步骤一路点，最后填上PAC文件的路径。</p>
<p>Network -&gt; Network proxy -&gt; Automatic -&gt; Configuration URL -&gt; <code>/etc/proxy/my.pac</code></p>
<h3 id="浏览器插件"><a href="#浏览器插件" class="headerlink" title="浏览器插件"></a>浏览器插件</h3><blockquote>
<p>2019-05-15 更新</p>
</blockquote>
<p>最近安装了几次 Ubuntu 18.04 都无法通过上述系统配置实现自动跳转，仅全局代理生效，尚未找出原因。</p>
<p>目前推荐的解决方案是通过 <code>SwitchyOmega</code> 等 chrome 插件设置自动代理，一次配置随处生效（也可以在单机上选择性关闭），操作更为方案，无须再到系统配置了。</p>
<ul>
<li>SwitchyOmega: <a href="https://github.com/FelisCatus/SwitchyOmega" target="_blank" rel="noopener">https://github.com/FelisCatus/SwitchyOmega</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      近期Evernote因为局域网问题不能使用了，作为重要工具不能离手，于是借助ss代理方式应急一下。ubuntu18没有特别好用的ss GUI，故选择了命令行工具ss-local。部署没难度，操作流程是翻文档加自己探索，个人认为比网上其他攻略简单，分享出来希望有助于大家解决网络疑难杂症。同时声明，本文只涉及客户端部署，evernote.com截止文章发布时间并没有被墙，请使用国内云服务器代理合规站点。
    
    </summary>
    
      <category term="Linux" scheme="https://claude-ray.github.io/categories/Linux/"/>
    
    
      <category term="Ubuntu" scheme="https://claude-ray.github.io/tags/Ubuntu/"/>
    
      <category term="proxy" scheme="https://claude-ray.github.io/tags/proxy/"/>
    
  </entry>
  
  <entry>
    <title>Jest共享server和tests的上下文环境</title>
    <link href="https://claude-ray.github.io/2018/10/30/jest-server-context/"/>
    <id>https://claude-ray.github.io/2018/10/30/jest-server-context/</id>
    <published>2018-10-30T14:05:19.000Z</published>
    <updated>2018-10-31T14:14:29.396Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>单元测试，test文件的加载顺序尤为关键。对于服务端，通常先启动http server，再通过发起接口请求的方式展开后续测试。</p>
<p>但仅仅controller层测试不能满足复杂业务的校验，需要对service及以下层级编写测试时，需要切入server的上下文环境才能做出恰当处理。</p>
<p>笔者尝试一番发现Jest并不能优雅地使用配置支持node.js server和test cases共享上下文环境，具体情况将在下文交代。</p>
<h1 id="Jest配置项说明"><a href="#Jest配置项说明" class="headerlink" title="Jest配置项说明"></a>Jest配置项说明</h1><p>jest倾向于将测试执行前的运行环境都加载配置(package.json的jest)中。因此我也先在官网<a href="https://jestjs.io/docs/en/configuration" target="_blank" rel="noopener">文档</a>中查询了相关配置项。</p>
<h2 id="globalSetup-string"><a href="#globalSetup-string" class="headerlink" title="globalSetup [string]"></a>globalSetup [string]</h2><blockquote>
<p>This option allows the use of a custom global setup module which exports an async function that is triggered once before all test suites. This function gets Jest’s globalConfig object as a parameter.</p>
</blockquote>
<p>通过字符串指定一个文件，其exports的函数作为初始化脚本，并支持异步操作。</p>
<p>jest运行测试过程中，此函数只会在所有测试用例加载前执行一次。用途可以是执行安装脚本，初始化数据库等。</p>
<p>需要特别注意的是，此函数运行的上下文环境与接下来的测试用例并无关联。</p>
<blockquote>
<p>详见issue <a href="https://github.com/facebook/jest/issues/6007" target="_blank" rel="noopener">https://github.com/facebook/jest/issues/6007</a></p>
</blockquote>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// test/setup.js</span></span><br><span class="line"><span class="built_in">module</span>.exports = <span class="keyword">async</span> () =&gt; &#123;</span><br><span class="line">  <span class="comment">// 这个变量并不会传到test case中</span></span><br><span class="line">  global.setup = <span class="string">'setup'</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="globalTeardown-string"><a href="#globalTeardown-string" class="headerlink" title="globalTeardown [string]"></a>globalTeardown [string]</h2><blockquote>
<p>This option allows the use of a custom global teardown module which exports an async function that is triggered once after all test suites. This function gets Jest’s globalConfig object as a parameter.</p>
</blockquote>
<p>同globalSetup，该异步函数只会在整个测试生命周期末执行一次。用途可以是运行环境重置，还原或drop数据库等。</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// test/teardown.js</span></span><br><span class="line"><span class="built_in">module</span>.exports = <span class="keyword">async</span> () =&gt; &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">`这里和<span class="subst">$&#123;global.setup&#125;</span>运行环境一致`</span>);</span><br><span class="line">  <span class="keyword">return</span> process.exit(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="testEnvironment-string"><a href="#testEnvironment-string" class="headerlink" title="testEnvironment [string]"></a>testEnvironment [string]</h2><p>通常是指定运行环境，默认浏览器，nodejs需要指定为<code>node</code>。</p>
<p>当然也可以指定为一个文件。该文件需要继承自<code>jest-environment-node</code>，并实现<code>setup</code>、<code>teardown</code>和<code>runScript</code>三个方法。</p>
<p>以官文的demo举例<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// test/env.js</span></span><br><span class="line"><span class="keyword">const</span> NodeEnvironment = <span class="built_in">require</span>(<span class="string">'jest-environment-node'</span>);</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomEnvironment</span> <span class="keyword">extends</span> <span class="title">NodeEnvironment</span> </span>&#123;</span><br><span class="line">  <span class="keyword">constructor</span>(config) &#123;</span><br><span class="line">    <span class="keyword">super</span>(config);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">async</span> setup() &#123;</span><br><span class="line">    <span class="keyword">await</span> <span class="keyword">super</span>.setup();</span><br><span class="line">    <span class="keyword">await</span> someSetupTasks();</span><br><span class="line">    <span class="keyword">this</span>.global.someGlobalObject = createGlobalObject();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">async</span> teardown() &#123;</span><br><span class="line">    <span class="keyword">this</span>.global.someGlobalObject = destroyGlobalObject();</span><br><span class="line">    <span class="keyword">await</span> someTeardownTasks();</span><br><span class="line">    <span class="keyword">await</span> <span class="keyword">super</span>.teardown();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  runScript(script) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">super</span>.runScript(script);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">module</span>.exports = CustomEnvironment;</span><br></pre></td></tr></table></figure></p>
<p>这里上下文环境支持通过<code>this.global</code>将变量共享到每个测试文件。</p>
<p><code>jest-environment-node</code>方法说明：</p>
<ul>
<li><p>setup: 每个test suit（通常指测试文件）执行一次，支持异步方法。</p>
</li>
<li><p>teardown: 每个test suit执行一次，支持异步方法。</p>
</li>
<li><p>runScript: 每个小的test都会执行一次，要求用同步，若为异步则执行顺序不可控制。</p>
</li>
</ul>
<h2 id="setupFiles-array"><a href="#setupFiles-array" class="headerlink" title="setupFiles [array]"></a>setupFiles [array]</h2><p>同env的setup。</p>
<h2 id="setupTestFrameworkScriptFile-string"><a href="#setupTestFrameworkScriptFile-string" class="headerlink" title="setupTestFrameworkScriptFile [string]"></a>setupTestFrameworkScriptFile [string]</h2><p>同env的runScript。</p>
<h1 id="Jest生命周期"><a href="#Jest生命周期" class="headerlink" title="Jest生命周期"></a>Jest生命周期</h1><p>了解jest常用的一些启动配置后，应该对加载顺序有了大概的认知。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">1.</span><br><span class="line">globaSetup -&gt;</span><br><span class="line"></span><br><span class="line">  2.</span><br><span class="line">  env.setup (every test suit) -&gt;</span><br><span class="line">  env.runScript (every test case) -&gt;</span><br><span class="line">  env.teardown (every test suit) -&gt;</span><br><span class="line"></span><br><span class="line">  3.</span><br><span class="line">  repeat...</span><br><span class="line"></span><br><span class="line">    n.</span><br><span class="line">    -&gt; globalTeardown</span><br></pre></td></tr></table></figure>
<h1 id="Context共享"><a href="#Context共享" class="headerlink" title="Context共享"></a>Context共享</h1><h2 id="调整Server启动位置"><a href="#调整Server启动位置" class="headerlink" title="调整Server启动位置"></a>调整Server启动位置</h2><p>根据不同的测试场景，选择合适的server启动位置：</p>
<ol>
<li><p>仅接口层测试。对测试代码的加载流程要求最低，只需要保证测试用例执行前启动http服务即可。可以加在jest的任何一环。如无特殊处理，http服务启动一次就好，放在globalSetup为妙。</p>
</li>
<li><p>多层测试，但controller和service之前耦合度较低，用global存储了少量运行信息。这种情况也简单，可以手动挂在this.global，使测试脚本和server的上下文环境相似。</p>
</li>
<li><p>多层测试，各模块耦合严重，上下文挂载了较多内容，不止global中存储的变量，对原生JS对象方法也做了修改。这时，通过jest的配置无法传递上下文。</p>
</li>
</ol>
<p>针对第三种情况，我选择将测试入口限制为单个文件(test suit)，其他测试文件用<code>require()</code>引入。此时，jest的env.setup和setupGlobal效果一致，因为jest认为只是启动了单个测试文件。如下，index.test.js的<code>beforeAll</code>具备了所有测试用例的最高优先级，保证server启动早于测试执行，并实现测试用例和server共享上下文。</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// test/index.test.js</span></span><br><span class="line"></span><br><span class="line">beforeAll(<span class="keyword">async</span> () =&gt; &#123;</span><br><span class="line">  <span class="comment">// launcher server</span></span><br><span class="line">  <span class="keyword">await</span> load();</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// require all test files</span></span><br><span class="line"><span class="built_in">require</span>(<span class="string">'./file.test.js'</span>);</span><br></pre></td></tr></table></figure>
<p>综上，总的package.json<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"name"</span>: <span class="string">"demo"</span>,</span><br><span class="line">  <span class="attr">"version"</span>: <span class="string">"0.0.1"</span>,</span><br><span class="line">  <span class="attr">"scripts"</span>: &#123;</span><br><span class="line">    <span class="attr">"test"</span>: <span class="string">"jest ./test/index"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"jest"</span>: &#123;</span><br><span class="line">    <span class="attr">"testEnvironment"</span>: <span class="string">"./test/env.js"</span>,</span><br><span class="line">    <span class="attr">"globalSetup"</span>: <span class="string">"./test/setup.js"</span>,</span><br><span class="line">    <span class="attr">"globalTeardown"</span>: <span class="string">"./test/teardown.js"</span>,</span><br><span class="line">    <span class="attr">"globals"</span>: &#123;</span><br><span class="line">      <span class="attr">"testBoolean"</span>: <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="其他方法"><a href="#其他方法" class="headerlink" title="其他方法"></a>其他方法</h2><p>参考egg的做法，统一将上下文放在app，并通过<code>egg-mock</code>来获取。</p>
]]></content>
    
    <summary type="html">
    
      本文首先简单介绍Jest关于启动的配置项，阐述Jest测试生命周期，之后粗略总结不同情况的server应该何时启动，最终使用略粗鄙的办法解决本次问题。
    
    </summary>
    
      <category term="Node.js" scheme="https://claude-ray.github.io/categories/Node-js/"/>
    
    
      <category term="Node.js" scheme="https://claude-ray.github.io/tags/Node-js/"/>
    
      <category term="Jest" scheme="https://claude-ray.github.io/tags/Jest/"/>
    
      <category term="Unit Testing" scheme="https://claude-ray.github.io/tags/Unit-Testing/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB升级4.0和事务使用小记</title>
    <link href="https://claude-ray.github.io/2018/10/23/update-mongod4/"/>
    <id>https://claude-ray.github.io/2018/10/23/update-mongod4/</id>
    <published>2018-10-23T14:08:09.000Z</published>
    <updated>2018-10-23T15:54:11.465Z</updated>
    
    <content type="html"><![CDATA[<p>4.0正式版已经出了3个多月，相比测试阶段网上有价值的资料日渐丰富，版本升级以及使用事务需要了解的知识都可以在官网找到。在这里记录一下升级本地开发环境的过程，生产环境应当用数据备份再恢复的方案。</p>
<p>总文档：<a href="https://docs.mongodb.com/manual/release-notes/4.0/" target="_blank" rel="noopener">Release Notes for MongoDB 4.0</a></p>
<h2 id="版本升级"><a href="#版本升级" class="headerlink" title="版本升级"></a>版本升级</h2><p>单机开发环境，参考<a href="https://docs.mongodb.com/manual/release-notes/4.0-upgrade-standalone/" target="_blank" rel="noopener">standalone升级文档</a></p>
<blockquote>
<p>以下升级流程节选自上述文档</p>
</blockquote>
<p>确保本地是3.6版本才能继续进行，以及兼容版本<code>featureCompatibilityVersion</code>为3.6。在mongo shell中可以执行检查和设置。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">db.adminCommand( &#123; getParameter: 1, featureCompatibilityVersion: 1 &#125; )</span><br><span class="line"></span><br><span class="line">db.adminCommand( &#123; setFeatureCompatibilityVersion: <span class="string">"3.6"</span> &#125; )</span><br></pre></td></tr></table></figure>
<p>升级前应关闭mongod服务和<strong>备份数据</strong>，之后按照官网所给出对应系统的<a href="https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/" target="_blank" rel="noopener">安装方法</a>执行安装。</p>
<p>例如Ubuntu18，可以按下面依次执行<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 9DA31620334BD75D9DCB49F368818C72E52529D4</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.0 multiverse"</span> | sudo tee /etc/apt/sources.list.d/mongodb-org-4.0.list</span><br><span class="line"></span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y mongodb-org</span><br></pre></td></tr></table></figure></p>
<p>升级完成后在mongo shell中重新设置兼容性<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.adminCommand( &#123; setFeatureCompatibilityVersion: <span class="string">"4.0"</span> &#125; )</span><br></pre></td></tr></table></figure></p>
<h2 id="事务使用"><a href="#事务使用" class="headerlink" title="事务使用"></a>事务使用</h2><h3 id="replSet"><a href="#replSet" class="headerlink" title="replSet"></a>replSet</h3><p>目前必须在replSet中使用，简单的配置方法是<code>/etc/mongod.conf</code>添加设置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">replication:</span><br><span class="line">  replSetName: rs0</span><br></pre></td></tr></table></figure></p>
<p>然后重启mongod <code>service mongod restart</code>，在mongo shell中执行初始化并查看结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rs.initiate()</span><br><span class="line">rs.conf()</span><br></pre></td></tr></table></figure></p>
<h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><p>官方使用教程，内含demo：<br><a href="https://docs.mongodb.com/manual/core/transactions/" target="_blank" rel="noopener">https://docs.mongodb.com/manual/core/transactions/</a></p>
<p>Nodejs相关文档（npm包需更新）：</p>
<ul>
<li><p>node-mongodb-native:<br><a href="http://mongodb.github.io/node-mongodb-native/3.1/api/ClientSession.html#startTransaction" target="_blank" rel="noopener">http://mongodb.github.io/node-mongodb-native/3.1/api/ClientSession.html#startTransaction</a></p>
</li>
<li><p>mongoose:<br><a href="https://mongoosejs.com/docs/transactions.html" target="_blank" rel="noopener">https://mongoosejs.com/docs/transactions.html</a></p>
</li>
</ul>
<p>手中项目使用事务的场景不多，暂时没有遇到坑，之后遇到再补充。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;4.0正式版已经出了3个多月，相比测试阶段网上有价值的资料日渐丰富，版本升级以及使用事务需要了解的知识都可以在官网找到。在这里记录一下升级本地开发环境的过程，生产环境应当用数据备份再恢复的方案。&lt;/p&gt;
&lt;p&gt;总文档：&lt;a href=&quot;https://docs.mongod
    
    </summary>
    
      <category term="MongoDB" scheme="https://claude-ray.github.io/categories/MongoDB/"/>
    
    
      <category term="MongoDB" scheme="https://claude-ray.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>koa之Content-Type与Content-Length</title>
    <link href="https://claude-ray.github.io/2018/10/18/koa-content/"/>
    <id>https://claude-ray.github.io/2018/10/18/koa-content/</id>
    <published>2018-10-18T14:16:05.000Z</published>
    <updated>2019-03-07T16:00:19.666Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Content-Type"><a href="#Content-Type" class="headerlink" title="Content-Type"></a>Content-Type</h1><p>众所周知，koa可以方便地通过<code>ctx.type=</code>来设置响应头的<code>Content-Type</code>。</p>
<p>但下面这段代码，当响应体ctx.body为<code>object</code>时，无论怎么设置ctx.type，收到的Content-Type都是<code>application/json</code>。</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ctx.type = <span class="string">'text/html'</span>;</span><br><span class="line">ctx.body = &#123; <span class="attr">type</span>: <span class="string">'json'</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 得到的content-type依然为application/json</span></span><br></pre></td></tr></table></figure>
<p>为什么设置被覆盖了，要通过一小段koa源码来解释。</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// koa/lib/response.js</span></span><br><span class="line"></span><br><span class="line">set body(val) &#123;</span><br><span class="line">  <span class="keyword">const</span> original = <span class="keyword">this</span>._body;</span><br><span class="line">  <span class="keyword">this</span>._body = val;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>.res.headersSent) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// no content</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="literal">null</span> == val) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!statuses.empty[<span class="keyword">this</span>.status]) <span class="keyword">this</span>.status = <span class="number">204</span>;</span><br><span class="line">    <span class="keyword">this</span>.remove(<span class="string">'Content-Type'</span>);</span><br><span class="line">    <span class="keyword">this</span>.remove(<span class="string">'Content-Length'</span>);</span><br><span class="line">    <span class="keyword">this</span>.remove(<span class="string">'Transfer-Encoding'</span>);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// set the status</span></span><br><span class="line">  <span class="keyword">if</span> (!<span class="keyword">this</span>._explicitStatus) <span class="keyword">this</span>.status = <span class="number">200</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// set the content-type only if not yet set</span></span><br><span class="line">  <span class="keyword">const</span> setType = !<span class="keyword">this</span>.header[<span class="string">'content-type'</span>];</span><br><span class="line"></span><br><span class="line">  <span class="comment">// string</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="string">'string'</span> == <span class="keyword">typeof</span> val) &#123;</span><br><span class="line">    <span class="keyword">if</span> (setType) <span class="keyword">this</span>.type = <span class="regexp">/^\s*&lt;/</span>.test(val) ? <span class="string">'html'</span> : <span class="string">'text'</span>;</span><br><span class="line">    <span class="keyword">this</span>.length = Buffer.byteLength(val);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// buffer</span></span><br><span class="line">  <span class="keyword">if</span> (Buffer.isBuffer(val)) &#123;</span><br><span class="line">    <span class="keyword">if</span> (setType) <span class="keyword">this</span>.type = <span class="string">'bin'</span>;</span><br><span class="line">    <span class="keyword">this</span>.length = val.length;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// stream</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="string">'function'</span> == <span class="keyword">typeof</span> val.pipe) &#123;</span><br><span class="line">    onFinish(<span class="keyword">this</span>.res, destroy.bind(<span class="literal">null</span>, val));</span><br><span class="line">    ensureErrorHandler(val, err =&gt; <span class="keyword">this</span>.ctx.onerror(err));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// overwriting</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">null</span> != original &amp;&amp; original != val) <span class="keyword">this</span>.remove(<span class="string">'Content-Length'</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (setType) <span class="keyword">this</span>.type = <span class="string">'bin'</span>;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// json</span></span><br><span class="line">  <span class="keyword">this</span>.remove(<span class="string">'Content-Length'</span>);</span><br><span class="line">  <span class="keyword">this</span>.type = <span class="string">'json'</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>熟悉koa源码的同学可能还记得，如果ctx.type未设置，会根据传给body的值类型赋予<code>Content-Type</code>默认值。</p>
<ul>
<li><code>null/undefined</code>：type什么的不存在的，即使有也会被删掉，并设置’No Content’ 204状态码</li>
<li><code>string</code>：正则<code>/^\s*&lt;/</code>匹配，分情况设为html或text</li>
<li><code>Buffer</code>：如果未设置type，那么会被改为<code>bin</code>(application/octet-stream)</li>
<li><code>Stream</code>：同Buffer，当然逻辑上会多个绑定结束时destroy和异常处理，如果和旧body不同，还会删掉content-length</li>
<li>以上都不是：即使设置过<code>ctx.type</code>，也会重新标记为json，并删除content-length</li>
</ul>
<p>可想而知，既然已经过每一步判断，body的内容一般就是<code>boolean</code>、<code>object</code>或<code>number</code>之流，标记为<code>json</code>合情合理。当然没忘<code>symbol</code>，它是无法被JSON序列化的，会抛出TypeError。</p>
<p>综上，如果接口返回值满足上述几个json类型，又想更改响应头的content-type，最简单的方法其实是<code>ctx.type=</code>放在<code>ctx.body=</code>之后，以重新覆盖响应头的内容。但一些路由中间件封装的时候没有考虑这层面，把接口返回值作为ctx.body，添加这种在body后设置type的操作可能会遇到困难。</p>
<p>另一种常规方法是调整数据格式后再对ctx.body赋值，例如对object进行JSON.stringify处理后，之前设置的content-type才不会被覆盖为<code>application/json</code>。</p>
<blockquote>
<p>ctx.type的设置支持各类缩略词，每次set前都会通过<code>mime-types</code>和<code>mime-db</code>依赖匹配完整名称，并挂上charset。</p>
</blockquote>
<blockquote>
<p>除了设置，还需要注意的点是ctx.type的getter会过滤掉<code>charset</code>部分，因此<strong>ctx.type的setter和getter不是完全对等的</strong>。如果想获取之前设置过的完整信息，需要通过<code>ctx.res.getHeader(&#39;Content-Type&#39;)</code>到头部获取。</p>
</blockquote>
<p>Wait，好像还漏了什么？</p>
<p>content-type既然在最后给定为json，为什么执行了一个<code>this.remove(&#39;Content-Length&#39;)</code>？且听下面分解。</p>
<h1 id="Content-Length"><a href="#Content-Length" class="headerlink" title="Content-Length"></a>Content-Length</h1><p>在<code>set body</code>的string和Buffer步骤，都会主动判断字节长度（不是字符，所以string用Buffer.byteLength判断），并对this.length即content-length赋值。而json和stream则相反，不但没有设置length，反而把设置过的删掉了。</p>
<p>简单分析一下，stream步骤的删除不难理解，二进制数据流只有传输完毕才能计算长度，不需要从响应头判断length。另一方面，content-length是允许胡乱设置的，koa为了避免它被设置一个错误的值，所以才有了的重新赋值与删除。甚至在异常捕获中也加上了这个fix：<a href="https://github.com/koajs/koa/issues/199" target="_blank" rel="noopener">Content-Length not reset if error is thrown after body is set</a>。</p>
<p>那么json返回值的length被删掉之后，它是从哪里重新被设置呢？</p>
<blockquote>
<p>最初我错想为交给了node底层处理，而且确实在http模块中有对content-length的设置，但它只有在完全未指定headers时才会添加。[<a href="https://github.com/nodejs/node/blob/master/lib/_http_outgoing.js]" target="_blank" rel="noopener">https://github.com/nodejs/node/blob/master/lib/_http_outgoing.js]</a></p>
</blockquote>
<p>实际对json类型的值判断字节长度非常容易，JSON.stringify加Buffer.byteLength即可。目录内搜索一下对this.length或ctx.length的赋值，果然，在响应的最终res.end()之前看到了该处理。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// koa/lib/application.js</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">respond</span>(<span class="params">ctx</span>) </span>&#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// responses</span></span><br><span class="line">  <span class="keyword">if</span> (Buffer.isBuffer(body)) <span class="keyword">return</span> res.end(body);</span><br><span class="line">  <span class="keyword">if</span> (<span class="string">'string'</span> == <span class="keyword">typeof</span> body) <span class="keyword">return</span> res.end(body);</span><br><span class="line">  <span class="keyword">if</span> (body <span class="keyword">instanceof</span> Stream) <span class="keyword">return</span> body.pipe(res);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// body: json</span></span><br><span class="line">  body = <span class="built_in">JSON</span>.stringify(body);</span><br><span class="line">  <span class="keyword">if</span> (!res.headersSent) &#123;</span><br><span class="line">    ctx.length = Buffer.byteLength(body);</span><br><span class="line">  &#125;</span><br><span class="line">  res.end(body);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>因此，一般我们对 json 类型的返回值显式更改 <code>ctx.length</code> 是没实际意义的，koa 的默认在 res.end 前强制把 length 覆盖。这个处理可以避免使用者错误地认为 body.length 就是响应数据的长度。</p>
<p>如果非要修改，去使用 ctx.res.writeHead 吧，如此一来，res.headersSent 内的处理就被会跳过了。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>koa的源码解析文章实在太多了，所以早先没有打算像express那样写一篇逐句分析，而且确实简单易读，<del>恐怕没写完就太监了</del>。但时间一久，很多细节就忘掉了，会遇到此类问题说明对其底层不够熟悉。就此写一篇笔记，发出来加深记忆。[真香.jpg]</p>
]]></content>
    
    <summary type="html">
    
      透过ctx.body setter的执行过程，分析koa如何设置响应头content-type和content-length，以及一些注意事项。
    
    </summary>
    
      <category term="Node.js" scheme="https://claude-ray.github.io/categories/Node-js/"/>
    
    
      <category term="Node.js" scheme="https://claude-ray.github.io/tags/Node-js/"/>
    
      <category term="JavaScript" scheme="https://claude-ray.github.io/tags/JavaScript/"/>
    
      <category term="Koa" scheme="https://claude-ray.github.io/tags/Koa/"/>
    
  </entry>
  
  <entry>
    <title>Nodejs使用MySQL 4.1的问题解决</title>
    <link href="https://claude-ray.github.io/2018/10/12/old-sms-mas-nodejs/"/>
    <id>https://claude-ray.github.io/2018/10/12/old-sms-mas-nodejs/</id>
    <published>2018-10-12T14:04:17.000Z</published>
    <updated>2018-10-31T14:14:55.144Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数据库连接"><a href="#数据库连接" class="headerlink" title="数据库连接"></a>数据库连接</h2><p>如果使用<code>old authentication</code>方式连接4.1版本之前的mysql，<code>sequelize</code>和<code>mysql2</code>无法通过认证：<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123; Error: Access denied <span class="keyword">for</span> user: <span class="string">'@127.0.0.x'</span> (Using password: NO)</span><br><span class="line">    at Packet.asError (/home/claude/Workspace/packages/sql/node_modules/mysql2/lib/packets/packet.js:714:13)</span><br><span class="line">    at ClientHandshake.Command.execute (/home/claude/Workspace/packages/sql/node_modules/mysql2/lib/commands/command.js:28:22)</span><br><span class="line">    at Connection.handlePacket (/home/claude/Workspace/packages/sql/node_modules/mysql2/lib/connection.js:513:28)</span><br><span class="line">    at PacketParser.onPacket (/home/claude/Workspace/packages/sql/node_modules/mysql2/lib/connection.js:81:16)</span><br><span class="line">    at PacketParser.executeStart (/home/claude/Workspace/packages/sql/node_modules/mysql2/lib/packet_parser.js:76:14)</span><br><span class="line">    at Socket.&lt;anonymous&gt; (/home/claude/Workspace/packages/sql/node_modules/mysql2/lib/connection.js:89:29)</span><br><span class="line">    at Socket.emit (events.js:182:13)</span><br><span class="line">    at addChunk (_stream_readable.js:283:12)</span><br><span class="line">    at readableAddChunk (_stream_readable.js:264:11)</span><br><span class="line">    at Socket.Readable.push (_stream_readable.js:219:10)</span><br><span class="line">    at TCP.onread (net.js:639:20)</span><br><span class="line">  code: <span class="string">'ER_ACCESS_DENIED_ERROR'</span>,</span><br><span class="line">  errno: 1045,</span><br><span class="line">  sqlState: <span class="string">''</span>,</span><br><span class="line">  sqlMessage:</span><br><span class="line">   <span class="string">'Access denied for user: \'</span>@127.0.0.x\<span class="string">' (Using password: NO)'</span> &#125;</span><br></pre></td></tr></table></figure></p>
<p>处理倒不困难，在不能改动数据库的情况下，可以改用npm包<code>mysql</code>。</p>
<h2 id="编码转换"><a href="#编码转换" class="headerlink" title="编码转换"></a>编码转换</h2><p>移动mas的接入文档有描述如下：</p>
<blockquote>
<p>mysql使用ISO8859-1编码，往db接口写入数据时应先把编码格式转化为ISO8859-1…</p>
</blockquote>
<p>上述编码实际为<code>latin1</code>，为早期mysql的默认编码。实际文档存在误导，未指出mas机的db接口是使用gbk编码写入的，因此将字符进行转化gbk再使用该接口即可，无需再将编码转为<code>latin1</code>。</p>
<p>但如果想从数据库中读取，同事在创建连接时指定了<code>charset=latin1</code>获取到的中文是乱码。</p>
<p>这涉及到mysql如何用<code>latin1</code>存储中文的问题：<code>latin1</code>为0x00 to 0xFF范围的单字节编码（<code>ASCII</code>是它的子集），理论上单字节范围可以无损存储数据，任意编码均可以用字节流形式存储。</p>
<p>也就是说，mas机写入之前用的是gbk字节流，读取时直接用nodejs默认的utf8编码自然不行。那么怎样读出二进制数据呢？在npm <code>mysql</code>库的README中搜索<code>buffer</code>字样，找到了如下方法。</p>
<p>mysqljs支持在query中自定义<a href="https://github.com/mysqljs/mysql#string" target="_blank" rel="noopener">typeCast</a>方法，可用于提取数据的步骤进行编码转换。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> mysql = <span class="built_in">require</span>(<span class="string">'mysql'</span>);</span><br><span class="line"><span class="keyword">const</span> iconv = <span class="built_in">require</span>(<span class="string">'iconv-lite'</span>);</span><br><span class="line"><span class="keyword">const</span> connection = mysql.createConnection(&#123;</span><br><span class="line">  host     : <span class="string">'localhost'</span>,</span><br><span class="line">  user     : <span class="string">'me'</span>,</span><br><span class="line">  password : <span class="string">'secret'</span>,</span><br><span class="line">  database : <span class="string">'my_db'</span>,</span><br><span class="line">  charset  : <span class="string">'latin1'</span></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">connection.connect();</span><br><span class="line"></span><br><span class="line">connection.query(&#123;</span><br><span class="line">  sql: <span class="string">'SELECT * FROM tbl_user'</span>,</span><br><span class="line">  typeCast: <span class="function">(<span class="params">field, next</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="comment">// converting `tbl_user.name` to utf8 string:</span></span><br><span class="line">    <span class="keyword">if</span> (field.name === <span class="string">'username'</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> iconv.decode(field.buffer(), <span class="string">'gbk'</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> next();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;, (error, results, fields) =&gt; &#123;</span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<p>其中typeCast的参数field包含</p>
<ul>
<li>type 字段类型，<code>VARCHAR</code>等（<a href="https://github.com/mysqljs/mysql/blob/master/lib/protocol/packets/RowDataPacket.js#L41" target="_blank" rel="noopener">详情链接</a>）</li>
<li>name 字段名</li>
<li>length 字段长度</li>
<li>table 表名</li>
<li>db 数据库名</li>
<li>…</li>
</ul>
<p>依此，其他更多问题都可以迎刃而解。</p>
<h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><ul>
<li><a href="https://blog.csdn.net/css_good/article/details/8809016" target="_blank" rel="noopener">mysql中的latin1支持中文</a>，CSDN有很多一样的文章，不清楚谁是原作者。</li>
<li><a href="https://kb.iu.edu/d/ahfr" target="_blank" rel="noopener">What are the differences between ASCII, ISO 8859, and Unicode?</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      近期有同学在玩一台老古董服务器，要使用node连上4.1版本的MySQL进行操作。并且不让改动数据库配置，凭啥？人家是移动提供的MAS……本文分享一下帮忙时填的坑，主要为解决“数据库连接”和“编码转换”问题。
    
    </summary>
    
      <category term="Node.js" scheme="https://claude-ray.github.io/categories/Node-js/"/>
    
    
      <category term="Node.js" scheme="https://claude-ray.github.io/tags/Node-js/"/>
    
      <category term="MySQL" scheme="https://claude-ray.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>node图形验证码实现</title>
    <link href="https://claude-ray.github.io/2018/09/02/node-image-captcha/"/>
    <id>https://claude-ray.github.io/2018/09/02/node-image-captcha/</id>
    <published>2018-09-02T13:46:55.000Z</published>
    <updated>2018-10-31T14:12:50.376Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements"></a>Requirements</h2><p>参考文档安装基础图形库，<a href="https://github.com/Automattic/node-canvas" target="_blank" rel="noopener">node-canvas</a>。</p>
<p>建议使用<code>npm install canvas@next</code>安装2.x版本，兼容Windows开发环境，接口功能更完善。</p>
<p>此外，MDN的<a href="https://developer.mozilla.org/zh-CN/docs/Web/API/CanvasRenderingContext2D" target="_blank" rel="noopener">canvas相关文档</a>也可以作为重要参考。</p>
<h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><blockquote>
<p><code>opts.*</code>标注的是需要自行完善的属性或方法。图形验证码作为系统安全的一环，就不开放源码了，请谅解。</p>
</blockquote>
<h3 id="1-创建canvas-ctx"><a href="#1-创建canvas-ctx" class="headerlink" title="1. 创建canvas ctx"></a>1. 创建canvas ctx</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> canvas = <span class="keyword">new</span> Canvas(opts.width, opts.height);</span><br><span class="line"><span class="keyword">const</span> ctx = canvas.getContext(<span class="string">'2d'</span>);</span><br></pre></td></tr></table></figure>
<h3 id="2-透明度"><a href="#2-透明度" class="headerlink" title="2. 透明度"></a>2. 透明度</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ctx.globalAlpha = opts.opacity;</span><br></pre></td></tr></table></figure>
<h3 id="3-背景色填充"><a href="#3-背景色填充" class="headerlink" title="3. 背景色填充"></a>3. 背景色填充</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ctx.fillStyle = opts.bgc;</span><br><span class="line">ctx.fillRect(<span class="number">0</span>, <span class="number">0</span>, opts.width, opts.height);</span><br></pre></td></tr></table></figure>
<h3 id="4-写字"><a href="#4-写字" class="headerlink" title="4. 写字"></a>4. 写字</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; opts.length; i++) &#123;</span><br><span class="line">  <span class="comment">// 字体和随机字号</span></span><br><span class="line">  ctx.font = <span class="string">`<span class="subst">$&#123;opts.fontSize&#125;</span>px <span class="subst">$&#123;opts.font&#125;</span>`</span>;</span><br><span class="line">  <span class="comment">// 颜色</span></span><br><span class="line">  ctx.fillStyle = opts.randomColor();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 旋转角度，使用save/restore保存之前填充的状态</span></span><br><span class="line">  ctx.save();</span><br><span class="line">  ctx.rotate(opts.randomAngle());</span><br><span class="line">  <span class="comment">// 填充字体</span></span><br><span class="line">  ctx.fillText(opts.text[i], opts.wordSpaceX, opts.wordSpaceY);</span><br><span class="line">  ctx.restore();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="5-干扰线"><a href="#5-干扰线" class="headerlink" title="5. 干扰线"></a>5. 干扰线</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 干扰线宽度</span></span><br><span class="line">ctx.lineWidth = opts.lineWidth;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; length - <span class="number">2</span>; i++) &#123;</span><br><span class="line">  ctx.strokeStyle = opts.randomColor();</span><br><span class="line">  <span class="comment">// 绘制路径起始点</span></span><br><span class="line">  ctx.beginPath();</span><br><span class="line">  <span class="comment">// 移动画笔</span></span><br><span class="line">  ctx.moveTo(opts.x1, opts.y1));</span><br><span class="line">  ctx.lineTo(opts.x2, opts.y2));</span><br><span class="line">  <span class="comment">// 画线</span></span><br><span class="line">  ctx.stroke();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="6-干扰点"><a href="#6-干扰点" class="headerlink" title="6. 干扰点"></a>6. 干扰点</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 根据密度计算个数</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; opts.pixelNum; i++) &#123;</span><br><span class="line">  ctx.fillStyle = opts.randomColor();</span><br><span class="line">  ctx.beginPath();</span><br><span class="line">  <span class="comment">// 用实心圆作为点</span></span><br><span class="line">  ctx.arc(opts.x, opts.y, opts.radius, <span class="number">0</span>, <span class="number">2</span> * <span class="built_in">Math</span>.PI);</span><br><span class="line">  ctx.fill();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后的图片产出分多种：<code>Buffer</code>，<code>DataUrl</code>和<code>Stream</code>，就从官方文档上看例子吧，注意1.x和2.x的版本差异。</p>
<h2 id="应急方案"><a href="#应急方案" class="headerlink" title="应急方案"></a>应急方案</h2><h3 id="背景色"><a href="#背景色" class="headerlink" title="背景色"></a>背景色</h3><p>挑选一些对人眼友好的颜色，随机筛选几个拼接成渐变色背景，可以略微提高识别成本。但对于成熟的破解算法无意义，如果和字体颜色过接近，用户识别也会特别痛苦。</p>
<p>举个简单的3段式，抛砖引玉。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> gradient = ctx.createLinearGradient(<span class="number">0</span>, <span class="number">0</span>, opts.width, opts.height);</span><br><span class="line"></span><br><span class="line">gradient.addColorStop(<span class="number">0</span>, opts.randomBGC());</span><br><span class="line">gradient.addColorStop(<span class="number">0.5</span>, opts.randomBGC());</span><br><span class="line">gradient.addColorStop(<span class="number">1</span>, opts.randomBGC());</span><br><span class="line"></span><br><span class="line">ctx.fillStyle = gradient;</span><br><span class="line">ctx.fillRect(<span class="number">0</span>, <span class="number">0</span>, opts.width, opts.height);</span><br></pre></td></tr></table></figure></p>
<h3 id="空心字体"><a href="#空心字体" class="headerlink" title="空心字体"></a>空心字体</h3><p>canvas原生支持的几个字体差别实在不大，有个技巧是绘制空心字体，在验证码被攻击时，可以加入支持应急，在攻击者没有准备的情况下，可以立刻起到拦截效果。</p>
<p>用法很简单，将上面写字用到的<code>fillStyle</code>替换为<code>strokeStyle</code>，<code>fillText</code>替换为<code>strokeText</code>。</p>
<h2 id="Lib选择"><a href="#Lib选择" class="headerlink" title="Lib选择"></a>Lib选择</h2><p>起初，使用<code>gm</code>和<code>GraphicsMagick</code>的组合，但经压测发现了严重的性能问题，在<a href="https://stackoverflow.com/questions/23795669/graphicsmagick-for-node-js-gm-module-performance" target="_blank" rel="noopener">StackOverFlow</a>上也看到了原因，于是决定更换绘图方案。</p>
<blockquote>
<p>The gm module calls out to a command-line tool. You might look at using graphicsmagick2 instead, which is an actual binding to the graphicsmagick library. Unfortunately there is no documentation, so you’ll have to read the source for that (which isn’t too long).</p>
</blockquote>
<p>测试了npm上几个热门验证码模块，有两种相对高效的实现</p>
<ol>
<li>c++调用canvas运行环境（node-canvas）</li>
<li>无外部依赖，纯js绘图（trek-captcha）</li>
</ol>
<p>两年以上没人维护的包没有进行测试，有个自称1200/s的ccap，按我的需求出图，效率不及上面的一半。</p>
<p>最终选择了性能出色的node-canvas。</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>以上用法是作者半年前尝试推行AI验证无果的无奈产物，终于在近期被大举攻破时宣告灭亡。</p>
<p>在AI面前，图形验证码的防御力是非常低的，建议处理验证码业务的各位趁早接入行为识别。</p>
<p>希望可以帮到有需要的同学。</p>
<p>Last but not least，附两篇他人的精彩调研：</p>
<ul>
<li><p><a href="https://www.jianshu.com/p/c63b78a373ad" target="_blank" rel="noopener">验证码WEB端产品调研（一）：Google reCAPTCHA</a></p>
</li>
<li><p><a href="https://www.jianshu.com/p/c64902f60c7c" target="_blank" rel="noopener">验证码WEB端产品调研（二）：极限验证</a></p>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      JS的图形验证码已有很多开源实现，可以直接用npm引入，但如果综合考虑性能和契合度时，还是亲自动手造一个好。当然实现起来并不复杂，且方便结合自身需求调整，在此分享一下使用node-canvas绘制验证码的几个心得。
    
    </summary>
    
      <category term="Node.js" scheme="https://claude-ray.github.io/categories/Node-js/"/>
    
    
      <category term="JavaScript" scheme="https://claude-ray.github.io/tags/JavaScript/"/>
    
      <category term="Captcha" scheme="https://claude-ray.github.io/tags/Captcha/"/>
    
      <category term="Canvas" scheme="https://claude-ray.github.io/tags/Canvas/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu16.04升级18.04LTS</title>
    <link href="https://claude-ray.github.io/2018/08/23/ubuntu16to18md/"/>
    <id>https://claude-ray.github.io/2018/08/23/ubuntu16to18md/</id>
    <published>2018-08-23T13:16:15.000Z</published>
    <updated>2018-10-08T14:11:40.364Z</updated>
    
    <content type="html"><![CDATA[<h2 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h2><h3 id="进度缓慢"><a href="#进度缓慢" class="headerlink" title="- 进度缓慢"></a>- 进度缓慢</h3><p>部分软件需要手动输入y/n来决定一些新旧配置项的取舍，长时间不去查看就会一直卡着。</p>
<h3 id="桌面崩溃"><a href="#桌面崩溃" class="headerlink" title="- 桌面崩溃"></a>- 桌面崩溃</h3><p>由于加了一些界面美化插件，非常担心桌面崩溃，果然更新了三分之一就跪了。</p>
<p>尝试注销桌面系统，过一会儿屏幕上只剩一个鼠标，凉凉。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pkill Xorg</span><br></pre></td></tr></table></figure></p>
<p>为了恢复工作，尝试重新安装<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install --reinstall ubuntu.desktop</span><br></pre></td></tr></table></figure></p>
<p>但提示<code>Could not get lock /var/lib/dpkg/lock</code>，尝试强制获取lock<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo rm /var/cache/apt/archives/lock</span><br><span class="line">sudo rm /var/lib/dpkg/lock</span><br></pre></td></tr></table></figure></p>
<p>这时再执行reinstall ubuntu.desktop时，提示需要<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg --configure -a</span><br></pre></td></tr></table></figure></p>
<p>电脑硬盘不好，漫长的等待。此时一边在命令行工作，一边，等到上面指令终于执行完毕，基本上心态已崩，揣着重装系统的念头，(此时一定要做好数据备份)。</p>
<p>继续尝试重启<code>shutdown now -r</code>无效，按提示<code>systemctl reboot -i</code>成功启动</p>
<h2 id="善后"><a href="#善后" class="headerlink" title="善后"></a>善后</h2><p>惊喜是一次重启就成功了，部分软件如redshift提示无法使用，原因是缺了一些依赖，重新下载即可。</p>
<p>但是打开浏览器发现无法上网，但系统提示网线已连接，第一反应是dns，修改了<code>/etc/resolv.conf</code>没效果，又习惯性用ssh测远程连接，再次失败陷入误区。当发现使用ip和端口可以访问服务时才彻底意识到是dns的问题。</p>
<h3 id="修改dns"><a href="#修改dns" class="headerlink" title="- 修改dns"></a>- 修改dns</h3><p>一般情况，使用DHCP就可以动态处理网络问题。当有修改必要时，需要注意新旧版本Ubuntu修改方式存在差异。</p>
<h4 id="16-04以下："><a href="#16-04以下：" class="headerlink" title="16.04以下："></a>16.04以下：</h4><p>旧版本的ubuntu修改dns有两种方式，并不包含直接修改<code>/etc/resolv.conf</code>。</p>
<p>编辑<code>/etc/resolvconf/resolv.conf.d/base</code>，文件初始内容为空，加上<code>nameserver 8.8.8.8</code>，之后需执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">resolvconf -u</span><br></pre></td></tr></table></figure></p>
<p>才会正确生效并写入<code>/etc/resolv.conf</code>。</p>
<p>另一种方式是直接修改<code>/etc/network/interfaces</code>。</p>
<h4 id="18-04："><a href="#18-04：" class="headerlink" title="18.04："></a>18.04：</h4><p>以上方法均不适用，因为Ubuntu18采用了<code>Netplan</code>，查看DNS配置应使用<code>systemd-resolve --status</code>，</p>
<p>可以停用<code>systemd-resolved</code>服务但不推荐，目前修改教程较少，之后会越来越多。（<a href="https://www.itzgeek.com/how-tos/linux/ubuntu-how-tos/netplan-how-to-configure-static-ip-address-in-ubuntu-18-04-using-netplan.html" target="_blank" rel="noopener">参考链接</a>）</p>
<h3 id="修复ssh"><a href="#修复ssh" class="headerlink" title="- 修复ssh"></a>- 修复ssh</h3><p>升级之后使用ssh提示<code>permission denied (publickey)</code>，最快排查办法是带上参数<code>-vvv</code>，我这里的错误是未指定私钥文件，使用<code>-i</code>加私钥路径可解。</p>
<p>当然不想每次都-i，因此可以将公钥私钥放在id_rsa，id_rsa.pub。同时不想每次都输入密码，执行<code>ssh-add ~/.ssh/id_dsa</code>。</p>
<p>注意密钥权限只能属于使用者，文件400权限就好，超过权限范围会提示Permissions too open。</p>
<h3 id="18-04部署攻略"><a href="#18-04部署攻略" class="headerlink" title="- 18.04部署攻略"></a>- 18.04部署攻略</h3><p>重装redshift时发现有人整理了一些安装指令，可以方便大家部署新系统。</p>
<p><a href="https://github.com/erikdubois/Ultimate-Ubuntu-18.04" target="_blank" rel="noopener">https://github.com/erikdubois/Ultimate-Ubuntu-18.04</a></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>由于桌面系统相当脆弱，一定要通过命令行来完成升级，也方便处理异常。出现问题升级不一定中断，不要急着重启，避免让问题严重到系统无法访问。</p>
<p>不要听信网上的无痛升级论，做好数据备份，谨慎操作。</p>
<h3 id="16-08-24更新"><a href="#16-08-24更新" class="headerlink" title="16-08-24更新"></a>16-08-24更新</h3><p>桌面系统再次崩溃，详情可以看这个<a href="https://bugs.launchpad.net/ubuntu/+source/gdm3/+bug/1779476" target="_blank" rel="noopener">Bug</a>，并且在论坛找到了非常相似的<a href="https://ubuntuforums.org/showthread.php?t=2391542" target="_blank" rel="noopener">遭遇</a>。</p>
<p>起初还不清楚是什么状况，试过了swapoff，gnome重装，gdm3降级，切换lightdm等等，看到bug反馈时终于决定接受了各位前人的重装解决方案。</p>
<p>顺便碰到了双系统不能上网问题，修复较容易，BIOS 关闭<code>wake on lan</code>，如果已经关闭就重新打开再关闭。</p>
]]></content>
    
    <summary type="html">
    
      上个月第一次收到升级推送，当时工作较重又担心出现问题就拒绝了。今天又收到推送，恰好本地没有怕丢的代码，但是经验不足，直接通过推送窗口点击了同意，接下来虚惊一场。次日，桌面系统再次崩溃，强烈建议不要升级而是彻底重装!
    
    </summary>
    
      <category term="Linux" scheme="https://claude-ray.github.io/categories/Linux/"/>
    
    
      <category term="Ubuntu" scheme="https://claude-ray.github.io/tags/Ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>阿里云验证码node接入</title>
    <link href="https://claude-ray.github.io/2018/07/31/%E9%98%BF%E9%87%8C%E4%BA%91%E9%AA%8C%E8%AF%81%E7%A0%81node%E6%8E%A5%E5%85%A5/"/>
    <id>https://claude-ray.github.io/2018/07/31/阿里云验证码node接入/</id>
    <published>2018-07-31T14:51:14.000Z</published>
    <updated>2018-10-31T14:16:55.885Z</updated>
    
    <content type="html"><![CDATA[<h2 id="文档地址"><a href="#文档地址" class="headerlink" title="文档地址"></a>文档地址</h2><p>首先放出<del>不是那么</del>重要的文档地址。</p>
<p>我认为值得看的是使用说明中的流程图，其他感兴趣的信息可以在文档左侧菜单查找。</p>
<ul>
<li><a href="https://help.aliyun.com/document_detail/66306.html" target="_blank" rel="noopener">滑动验证使用说明</a></li>
<li><a href="https://help.aliyun.com/document_detail/66349.html" target="_blank" rel="noopener">签名机制</a></li>
<li><a href="https://develop.aliyun.com/tools/sdk" target="_blank" rel="noopener">阿里云全部SDK</a></li>
</ul>
<p>明明很重要的参数说明，太坑了，看不看都一样。</p>
<ul>
<li><a href="https://help.aliyun.com/document_detail/66340.html" target="_blank" rel="noopener">验证码服务端API</a></li>
<li><a href="https://help.aliyun.com/document_detail/66348.html" target="_blank" rel="noopener">公共参数</a></li>
</ul>
<h2 id="接入流程"><a href="#接入流程" class="headerlink" title="接入流程"></a>接入流程</h2><p>不得不说接入过程比geetest痛苦多了，后续会上传相关代码以供参考。关键是阿里云验证码版本号太多，我不想维护一个非官方SDK，因此也不会发布npm。</p>
<h3 id="1-阿里云控制台"><a href="#1-阿里云控制台" class="headerlink" title="1. 阿里云控制台"></a>1. 阿里云控制台</h3><ul>
<li>添加用户，拿到<code>AccessKeyID</code>和<code>AccessKeySecret</code></li>
<li>在<code>安全</code>-&gt;<code>数据风控</code>配置验证码，拿到<code>AppKey</code>，同时可获取接入demo。(虽然配置时要选择使用场景，而且只能靠单选生成一个<code>original scene</code>，实际使用时<code>Scene</code>参数可以自定义传递。)</li>
</ul>
<h3 id="2-下载其他版本SDK"><a href="#2-下载其他版本SDK" class="headerlink" title="2. 下载其他版本SDK"></a>2. 下载其他版本SDK</h3><p>很有必要，踩的坑全靠这一步来填。这里选择了php版sdk，前面提到阿里文档的参数并不准确，重点看以下文件补全参数。</p>
<ul>
<li><code>aliyun-php-sdk-afs/afs/Request/V20180112/AuthenticateSigRequest.php</code></li>
<li><code>aliyun-php-sdk-core/RpcAcsRequest.php</code></li>
</ul>
<h3 id="3-计算签名"><a href="#3-计算签名" class="headerlink" title="3. 计算签名"></a>3. 计算签名</h3><p>官方文档还算详细，更方便的是直接参考阿里云node-sdk的开源实现，如<code>https://github.com/willin/waliyun</code>。</p>
<blockquote>
<p>请求方式的不同，会决定signature是否需要经过编码。</p>
</blockquote>
<h3 id="4-HTTPS请求"><a href="#4-HTTPS请求" class="headerlink" title="4. HTTPS请求"></a>4. HTTPS请求</h3><p>GET和POST都支持，只需留意签名计算的区别。<br>为了避免各种请求模块对参数的编码进行再次转换，省心的做法是拼接完整url后使用GET请求。</p>
<h3 id="5-付费模式"><a href="#5-付费模式" class="headerlink" title="5. 付费模式"></a>5. 付费模式</h3><p>友情提示一下，官网明说<code>免费调用周期7天</code>，结果试用两天就收到0.08元欠费通知，找了半天没看到扣费明细，心塞T_T</p>
<p>应该是直接进入了后付费模式，因此测试时请做好心理准备。</p>
<h2 id="心得"><a href="#心得" class="headerlink" title="心得"></a>心得</h2><p>不可轻信文档，特别是神奇的日期格式版本号Version，公共参数居然给定了取值<code>2016-11-23</code>，但没给验证地址。</p>
<p>事实上新旧Version的验证地址并不相同。在不知情时用错误地址进行校验，一直提示InvalidVersion，并且没有对应的错误返回值文档。</p>
<p>除了验证地址，不同Version下需要提交的必选参数也不同，详情需要去其他版本SDK挖掘。</p>
<p>看得出文档内容比前人吐槽的时候丰富了不少，望相关开发人员及时更新。</p>
<h3 id="SDK实现"><a href="#SDK实现" class="headerlink" title="SDK实现"></a>SDK实现</h3><p><a href="https://github.com/Claude-Ray/aliyun-captcha" target="_blank" rel="noopener">aliyun-captcha</a></p>
]]></content>
    
    <summary type="html">
    
      分享接入过程和心得
    
    </summary>
    
      <category term="Node.js" scheme="https://claude-ray.github.io/categories/Node-js/"/>
    
    
      <category term="Node.js" scheme="https://claude-ray.github.io/tags/Node-js/"/>
    
      <category term="Captcha" scheme="https://claude-ray.github.io/tags/Captcha/"/>
    
  </entry>
  
  <entry>
    <title>解决svn没有merge全部更改的问题</title>
    <link href="https://claude-ray.github.io/2018/03/19/%E8%A7%A3%E5%86%B3svn%E6%B2%A1%E6%9C%89merge%E5%85%A8%E9%83%A8%E6%9B%B4%E6%94%B9%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>https://claude-ray.github.io/2018/03/19/解决svn没有merge全部更改的问题/</id>
    <published>2018-03-19T03:53:52.000Z</published>
    <updated>2018-03-19T16:59:53.809Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>今天使用svn合并主干到发布分支时，发现即使没有冲突，也出现了文件错误。检查后发现，文件内有一部分历史更改被遗漏了。</p>
<p>准确的说，上一次合并开发分支到主干后，由于只想发布个别文件（individual files），在发布分支merge拉取后只选择性的commit了4个文件，其他的文件（并非首次创建）更改自此忽略。记本次为操作A。</p>
<p>正常情况下，重新执行merge，仍然可以看到未提交的改动文件，但本次merge隔操作A数个版本之后，<code>mergeinfo</code>也并不会显示操作A漏掉的提交。</p>
<h2 id="解决过程"><a href="#解决过程" class="headerlink" title="解决过程"></a>解决过程</h2><h3 id="1-ignore-ancestry"><a href="#1-ignore-ancestry" class="headerlink" title="1. ignore ancestry"></a>1. ignore ancestry</h3><p>除了操作A之外，也有很多其他只提交特定文件的merge记录，所以直接加<code>--ignore-ancestry</code>，甚至出现了以下错误导致无法合并。<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">svn: E200004: Cannot merge automatically <span class="keyword">while</span> ignoring mergeinfo</span><br></pre></td></tr></table></figure></p>
<h3 id="2-指定版本号"><a href="#2-指定版本号" class="headerlink" title="2. 指定版本号"></a>2. 指定版本号</h3><p>指定被漏掉更改的那个版本号（例如r233），可以只找回当时漏提交的文件(使用参数<code>-c</code>, 限定ARG-1:ARG的修改)。</p>
<p>完整命令如下：<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">svn merge --ignore-ancestry -c 233 http://localhost/svn/url</span><br></pre></td></tr></table></figure></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>笔者对svn使用仍不够熟练，一直使用命令行操作，可能这也是触发霉头的根源。 XD</p>
<p>粗略浏览了Stack Overflow，没看到期望的答案，但有些回答也给我一些启发，捡一条附在了下面。</p>
<h4 id="相关问题"><a href="#相关问题" class="headerlink" title="相关问题"></a>相关问题</h4><p><a href="https://stackoverflow.com/questions/754082/merging-across-branches-in-subversion-isnt-adding-all-the-new-files-why-not" target="_blank" rel="noopener">Merging across branches in Subversion isn’t adding all the new files. Why not?
</a></p>
<p>The following statement is not true:</p>
<blockquote>
<p>Files that were added to a branch and then changed on the branch don’t get added when doing a merge across number of revisions</p>
</blockquote>
<p>That would imply merging is totally broken.</p>
<p>When you do the merge, you need to make sure that you do merge the revision that created the file, otherwise you’ll get those warnings about no target.</p>
<p>The other thing to watch out for is if you do a merge into a working copy, then decide you’re not happy with it and revert everything, the newly added files will still be in the working copy, so if you merge again, the unversioned files will prevent the merge of new files there, so you will miss them. So running “svn status” and removing unversioned files will ensure the merge works properly.</p>
<p>The comment about adding an empty file should not be done, because then the new file has no history of where it came from. In other words, it’s not a copy, so “svn log” will not show its history. And finally, if the file were a gigabyte photo, you wouldn’t want to merge it into a new file, because then the repository would have two copies of the exact same context. Merging and copying with history saves repository storage (at least until rep-sharing is put in).</p>
]]></content>
    
    <summary type="html">
    
      记一次svn merge individual files导致后续merge遗漏更改的解决方案。
    
    </summary>
    
      <category term="SVN" scheme="https://claude-ray.github.io/categories/SVN/"/>
    
    
      <category term="SVN" scheme="https://claude-ray.github.io/tags/SVN/"/>
    
  </entry>
  
</feed>
